{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Azure TRE Overview Trusted Research Environments (TRE) enforce a secure boundary around distinct workspaces to enable information governance controls to be enforced. A Trusted Research Environment (typically one per organization, or one per department in large organizations) consist of: One Composition Service (API, deployment engine etc. used to manage and deploy workspaces, workspace services and user resources) One set of Shared Services used by all workspaces A number of Workspaces , where each workspace is its own security boundary, and in turn contains Workspace Services and User Resources The Composition Service The Composition Service offers an abstraction over the lower-level Azure resources to allow for TRE users to provision resources in terms of workspaces and workspace services. The Composition Service reconciles the desired state with the actual state by invoking Azure resource deployments. The composition service is fronted by an API that helps the TRE Admin, TRE Workspace Owners and TRE Researchers create and manage the workspaces and workspace services . Shared Services A service provides one or more capabilities to you as a user of the TRE or to the TRE itself. Depending on the type of the service it is scoped to the environment and shared across all workspaces (Shared Service) or scoped to a specific workspace (Workspace Service). The types of services required for a research project varies greatly why extensibility is a key aspect of the Azure TRE solution. New services can be developed by you and your organization to fit your needs. Shared Services are services and resource shared by all workspaces. These services are created once, when the TRE is deployed and managed by the TRE Administrator. Examples of shared services are: Firewall Package Mirror Git Mirror Workspace A workspace is a set of resources on a network, with inbound traffic restricted to authorised users, and outbound access restricted to defined network locations. The workspace is a security boundary and there should be zero transfer of data out from the workspace unless explicitly configured. Data transfer is not restricted within a workspace. The workspace itself contains only the bare essentials to provide this functionality, such as firewalls, storage etc. Workspaces can be enhanced with one or more building blocks called workspace services like Azure ML, Guacamole etc. to allow functionality such as development of machine learning models, data engineering, data analysis and software development. Multiple workspaces can be created within a single Trusted Research Environment to enable the required separation for your projects. Each workspace has workspace users : a workspace owner (normally only one), and one or more workspace researchers that can access the data and workspace services in the workspace. The workspace owner is also considered a workspace researcher. Workspace Service A workspace service is a service, created as a building block, with pre-configured set of resources that can be applied to a workspace. Examples of Workspace Services are: Guacamole (Virtual Desktops) Azure Machine Learning Unlike shared services, a workspace service is only accessible to the workspace users. Some workspace services, such as Guacamole, allow users to add on user-specific resources (user resources) All workspace services can be deployed to all workspaces. User Resource A user resource is a resource that is only available to a particular researcher. For example a virtual machine exposed by Guacamole. User resources can be deployed to workspaces with a compatible workspace service. E.g. Guacamole VMs can only be deployed to workspaces where the Guacamole workspace service is deployed. Templates In order to deploy resources (workspaces, workspace services, user resources), the resources have to be defined in templates. A template contains everything needed to create an instance of the resource. Ex. a base workspace template, or a Guacamole workspace service template. The templates describe the porter bundles used, and the input parameters needed to deploy them. To use a template, and deploy a resource, the template needs to be registered in the TRE. This is done using the TRE API. Tip Once a template is registered it can be used multiple times to deploy multiple workspaces, workspace services etc. If you want to author your own workspace, workspace service, or user resource template, consult the template authoring guide","title":"Concepts"},{"location":"#azure-tre-overview","text":"Trusted Research Environments (TRE) enforce a secure boundary around distinct workspaces to enable information governance controls to be enforced. A Trusted Research Environment (typically one per organization, or one per department in large organizations) consist of: One Composition Service (API, deployment engine etc. used to manage and deploy workspaces, workspace services and user resources) One set of Shared Services used by all workspaces A number of Workspaces , where each workspace is its own security boundary, and in turn contains Workspace Services and User Resources","title":"Azure TRE Overview"},{"location":"#the-composition-service","text":"The Composition Service offers an abstraction over the lower-level Azure resources to allow for TRE users to provision resources in terms of workspaces and workspace services. The Composition Service reconciles the desired state with the actual state by invoking Azure resource deployments. The composition service is fronted by an API that helps the TRE Admin, TRE Workspace Owners and TRE Researchers create and manage the workspaces and workspace services .","title":"The Composition Service"},{"location":"#shared-services","text":"A service provides one or more capabilities to you as a user of the TRE or to the TRE itself. Depending on the type of the service it is scoped to the environment and shared across all workspaces (Shared Service) or scoped to a specific workspace (Workspace Service). The types of services required for a research project varies greatly why extensibility is a key aspect of the Azure TRE solution. New services can be developed by you and your organization to fit your needs. Shared Services are services and resource shared by all workspaces. These services are created once, when the TRE is deployed and managed by the TRE Administrator. Examples of shared services are: Firewall Package Mirror Git Mirror","title":"Shared Services"},{"location":"#workspace","text":"A workspace is a set of resources on a network, with inbound traffic restricted to authorised users, and outbound access restricted to defined network locations. The workspace is a security boundary and there should be zero transfer of data out from the workspace unless explicitly configured. Data transfer is not restricted within a workspace. The workspace itself contains only the bare essentials to provide this functionality, such as firewalls, storage etc. Workspaces can be enhanced with one or more building blocks called workspace services like Azure ML, Guacamole etc. to allow functionality such as development of machine learning models, data engineering, data analysis and software development. Multiple workspaces can be created within a single Trusted Research Environment to enable the required separation for your projects. Each workspace has workspace users : a workspace owner (normally only one), and one or more workspace researchers that can access the data and workspace services in the workspace. The workspace owner is also considered a workspace researcher.","title":"Workspace"},{"location":"#workspace-service","text":"A workspace service is a service, created as a building block, with pre-configured set of resources that can be applied to a workspace. Examples of Workspace Services are: Guacamole (Virtual Desktops) Azure Machine Learning Unlike shared services, a workspace service is only accessible to the workspace users. Some workspace services, such as Guacamole, allow users to add on user-specific resources (user resources) All workspace services can be deployed to all workspaces.","title":"Workspace Service"},{"location":"#user-resource","text":"A user resource is a resource that is only available to a particular researcher. For example a virtual machine exposed by Guacamole. User resources can be deployed to workspaces with a compatible workspace service. E.g. Guacamole VMs can only be deployed to workspaces where the Guacamole workspace service is deployed.","title":"User Resource"},{"location":"#templates","text":"In order to deploy resources (workspaces, workspace services, user resources), the resources have to be defined in templates. A template contains everything needed to create an instance of the resource. Ex. a base workspace template, or a Guacamole workspace service template. The templates describe the porter bundles used, and the input parameters needed to deploy them. To use a template, and deploy a resource, the template needs to be registered in the TRE. This is done using the TRE API. Tip Once a template is registered it can be used multiple times to deploy multiple workspaces, workspace services etc. If you want to author your own workspace, workspace service, or user resource template, consult the template authoring guide","title":"Templates"},{"location":"azure-tre-overview/architecture/","text":"Azure TRE Architecture The Azure Trusted Research Environment (TRE) consists of multiple components, all encapsulated in networks with restricted ingress- & egress traffic. There is one network for the core components and one network per Workspace. All traffic has to be explicitly allowed by the Application Gateway or the Firewall. The Azure resources outside the network boundries of the Azure TRE are Azure Active Directory, Microsoft Graph and TRE Management. TRE Management are resources used during deployment. The Azure TRE core plane consists of two groups of components: API & Composition Service Shared Services Todo The Shared Services #23 and Firewall Shared Service #882 are still work in progress. The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace. The Composition Service is doing the actual work of mutating the state of each Workspace including the Workspace Services. Ingress/egress components governs all inbound and outbound traffic from the public Internet to and from Azure TRE including the Workspaces. The Firewall Service is managing the egress rules of the Firewall. Shared Services are services available to all Workspaces. Source Mirror can mirror source repositories such as GitHub, but only allowing read-access, hence data from a Workspace cannot be pushed to a source repository. Package Mirror is also a read-only front for developer/researcher application package services like NPM, PyPI, and NuGet and operating system application package services like apt-get and Windows Package Manager (winget). Azure Resources The following diagram shows the Azure components deployed as part of a typical TRE deployment. The exact configuration will vary depending on the specific deployment. Composition Service The Composition Service is responsible for managing and mutating Workspaces and Workspace Services. It consists of multiple components: Component Name Responsibility / Description TRE API An API responsible for performing all operations on Workspaces and managing Workspace Templates. Configuration Store Keeping the state of Workspaces and Workspace Templates. The store uses Cosmos DB (SQL) . Service Bus Azure Service Bus responsible for reliable delivery of messages between components. Resource Processor Responsible for starting the process of mutating a Workspace via a Workspace Template. A Workspace is an instance of a Workspace Template. A Workspace Template is implemented as a Porter bundle - read more about Authoring workspaces templates . A Porter bundle is a fully encapsulated versioned bundle with everything needed (binaries, scripts, IaC templates etc.) to provision an instance of Workspace Template. To automate Porter it needs a place to live in Azure TRE. The home chosen for Porter to run was a Linux virtual machine. This Azure TRE component encompassing Porter and its dependencies is called Resource Processor . During the deployment of Resource Processor itself it is given the credentials of a managed identity with the privileges to modify and deploy resources to the subscription associated with the Azure TRE instance. Resource Processor later then uses these credentials to receive and send Service Bus messages, authorizes Porter to deploy Porter bundles and to access the storage account to update installation data. The logic in Resource Processor is written in Python. The Resource Processor implementation is located in resource_processor folder of the repository. The TRE Administrator can register a Porter bundle to use the Composition Service to provision instances of the Workspace Templates. This requires: The Porter bundle to be pushed to the Azure Container Registry (ACR). Registering the Workspace through the API. Details on how to register a Workspace Template . Provisioning a Workspace The flow to provision a Workspace is as follows (the flow is the same for all kinds of mutations to a Workspace): TRE Admin sends an HTTP request to the TRE API to create a new Workspace. The request contains information like the name of the Workspace, the Workspace Template to use, and the parameters required for the Workspace Template (Workspace Templates can expose the parameters via a JSON Schema ). The API saves the desired state of the Workspace in the Configuration Store. The API sends a command message with the Workspace Template reference and parameters to the workspacequeue . { \"action\" : \"install\" , \"id\" : \"base\" , \"name\" : \"BaseWorkspaceTemplate\" , \"version\" : \"1.0\" , \"parameters\" : { \"param1\" : \"value1\" } } The Resource Processor picks up the new message from the service bus queue. The Resource Processor processes the command by executing the Porter bundle (the implementation of a Workspace Template). # simplified for readability porter <action> --reference <ACR name>.azurecr.io/bundles/<name>:<version> --params key = value --cred <credentials set name or file> # Example porter install --reference msfttreacr.azurecr.io/bundles/BaseWorkspaceTemplate:1.0 --params param1 = value1 --cred azure.json Deployments are carried out against the Azure Subscription using a User Assigned Managed Identity. The azure.json tells Porter where the credential information can be found and for the Resource Processor they are set as environment variables. Porter bundle actions are required to be idempotent, so if a deployment fails, the Resource Processor can retry. The Porter Docker bundle is pulled from the Azure Container Registry (ACR) and executed. The Porter bundle executes against Azure Resource Manager to provision Azure resources. Any kind of infrastructure of code frameworks like ARM, Terraform, or Pulumi can be used or scripted via PowerShell or Azure CLI. Porter stores state and outputs in Azure Storage Containers. State for keeping persistent state between executions of a bundled with the same Workspace. For the time being, the Porter bundle updates Firewall rules directly setting egress rules. An enhancement to implement a Shared Firewall services is planned ( #882 ). The Resource Processor sends events to the deploymentstatus queue on state changes and informs if the deployment succeeded or failed. The API receives the status of the Porter bundle execution. The API updates the status of the Porter bundle execution in the Configuration Store.","title":"Architecture"},{"location":"azure-tre-overview/architecture/#azure-tre-architecture","text":"The Azure Trusted Research Environment (TRE) consists of multiple components, all encapsulated in networks with restricted ingress- & egress traffic. There is one network for the core components and one network per Workspace. All traffic has to be explicitly allowed by the Application Gateway or the Firewall. The Azure resources outside the network boundries of the Azure TRE are Azure Active Directory, Microsoft Graph and TRE Management. TRE Management are resources used during deployment. The Azure TRE core plane consists of two groups of components: API & Composition Service Shared Services Todo The Shared Services #23 and Firewall Shared Service #882 are still work in progress. The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace. The Composition Service is doing the actual work of mutating the state of each Workspace including the Workspace Services. Ingress/egress components governs all inbound and outbound traffic from the public Internet to and from Azure TRE including the Workspaces. The Firewall Service is managing the egress rules of the Firewall. Shared Services are services available to all Workspaces. Source Mirror can mirror source repositories such as GitHub, but only allowing read-access, hence data from a Workspace cannot be pushed to a source repository. Package Mirror is also a read-only front for developer/researcher application package services like NPM, PyPI, and NuGet and operating system application package services like apt-get and Windows Package Manager (winget).","title":"Azure TRE Architecture"},{"location":"azure-tre-overview/architecture/#azure-resources","text":"The following diagram shows the Azure components deployed as part of a typical TRE deployment. The exact configuration will vary depending on the specific deployment.","title":"Azure Resources"},{"location":"azure-tre-overview/architecture/#composition-service","text":"The Composition Service is responsible for managing and mutating Workspaces and Workspace Services. It consists of multiple components: Component Name Responsibility / Description TRE API An API responsible for performing all operations on Workspaces and managing Workspace Templates. Configuration Store Keeping the state of Workspaces and Workspace Templates. The store uses Cosmos DB (SQL) . Service Bus Azure Service Bus responsible for reliable delivery of messages between components. Resource Processor Responsible for starting the process of mutating a Workspace via a Workspace Template. A Workspace is an instance of a Workspace Template. A Workspace Template is implemented as a Porter bundle - read more about Authoring workspaces templates . A Porter bundle is a fully encapsulated versioned bundle with everything needed (binaries, scripts, IaC templates etc.) to provision an instance of Workspace Template. To automate Porter it needs a place to live in Azure TRE. The home chosen for Porter to run was a Linux virtual machine. This Azure TRE component encompassing Porter and its dependencies is called Resource Processor . During the deployment of Resource Processor itself it is given the credentials of a managed identity with the privileges to modify and deploy resources to the subscription associated with the Azure TRE instance. Resource Processor later then uses these credentials to receive and send Service Bus messages, authorizes Porter to deploy Porter bundles and to access the storage account to update installation data. The logic in Resource Processor is written in Python. The Resource Processor implementation is located in resource_processor folder of the repository. The TRE Administrator can register a Porter bundle to use the Composition Service to provision instances of the Workspace Templates. This requires: The Porter bundle to be pushed to the Azure Container Registry (ACR). Registering the Workspace through the API. Details on how to register a Workspace Template .","title":"Composition Service"},{"location":"azure-tre-overview/architecture/#provisioning-a-workspace","text":"The flow to provision a Workspace is as follows (the flow is the same for all kinds of mutations to a Workspace): TRE Admin sends an HTTP request to the TRE API to create a new Workspace. The request contains information like the name of the Workspace, the Workspace Template to use, and the parameters required for the Workspace Template (Workspace Templates can expose the parameters via a JSON Schema ). The API saves the desired state of the Workspace in the Configuration Store. The API sends a command message with the Workspace Template reference and parameters to the workspacequeue . { \"action\" : \"install\" , \"id\" : \"base\" , \"name\" : \"BaseWorkspaceTemplate\" , \"version\" : \"1.0\" , \"parameters\" : { \"param1\" : \"value1\" } } The Resource Processor picks up the new message from the service bus queue. The Resource Processor processes the command by executing the Porter bundle (the implementation of a Workspace Template). # simplified for readability porter <action> --reference <ACR name>.azurecr.io/bundles/<name>:<version> --params key = value --cred <credentials set name or file> # Example porter install --reference msfttreacr.azurecr.io/bundles/BaseWorkspaceTemplate:1.0 --params param1 = value1 --cred azure.json Deployments are carried out against the Azure Subscription using a User Assigned Managed Identity. The azure.json tells Porter where the credential information can be found and for the Resource Processor they are set as environment variables. Porter bundle actions are required to be idempotent, so if a deployment fails, the Resource Processor can retry. The Porter Docker bundle is pulled from the Azure Container Registry (ACR) and executed. The Porter bundle executes against Azure Resource Manager to provision Azure resources. Any kind of infrastructure of code frameworks like ARM, Terraform, or Pulumi can be used or scripted via PowerShell or Azure CLI. Porter stores state and outputs in Azure Storage Containers. State for keeping persistent state between executions of a bundled with the same Workspace. For the time being, the Porter bundle updates Firewall rules directly setting egress rules. An enhancement to implement a Shared Firewall services is planned ( #882 ). The Resource Processor sends events to the deploymentstatus queue on state changes and informs if the deployment succeeded or failed. The API receives the status of the Porter bundle execution. The API updates the status of the Porter bundle execution in the Configuration Store.","title":"Provisioning a Workspace"},{"location":"azure-tre-overview/networking/","text":"Network Architecture The Trusted Research Environment (TRE) network topology is based on hub-spoke . The TRE Core VNET ( Azure Virtual Network ) is the central hub and each workspace is a spoke. Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The security rules are managed by nsg-ws network security group. See workspace network security groups (NSG) further down. The Core VNET is further divided into subnets. Subnet Description AzureBastionSubnet A dedicated subnet for Azure Bastion hosts. AppGwSubnet Subnet for Azure Application Gateway controlling ingress traffic. AzureFirewallSubnet Subnet for Azure Firewall controlling egress traffic. ResourceProcessorSubnet Subnet for VMSS used by the Composition Service to host Docker containers to execute Porter bundles that deploys Workspaces. WebAppSubnet Subnet for TRE API. SharedSubnet Shared Services subnet for all things shared by TRE Core and Workspaces. Such as Source Mirror Shared Service and Package Mirror Shared Service. All subnets (Core and Workspace subnets) have a default route which directs egress traffic to the Azure Firewall to ensure only explicitly allowed destinations on the Internet to be accessed. There are a couple of exceptions: AzureFirewallSubnet as it hosts the Azure Firewall which routes traffic to the Internet. AzureBastionSubnet as it hosts Azure Bastion which is the management jump box within the VNET with Internet access. AppGwSubnet as it hosts the Azure Application Gateway which has to be able to a ping the health endpoints e.g. TRE API. Ingress and egress Ingress traffic from the Internet is only allowed through the Application Gateway, which forwards HTTPS (port 443) call to the TRE API in the WebAppSubnet . Egress traffic is routed through the Azure Firewall with a few exceptions and by default all ingress and egress traffic is denied except explicitly allowed. The explicitly allowed egress traffic is described here: Resource Processor TRE API Gitea Shared Service Nexus Shared Service Azure Monitor Azure Monitor resources are secured using Azure Monitor Private Link Scope (AMPLS) keeping all traffic inside the Microsoft Azure backbone network. The Azure Monitor resources and their network configuration is defined in /templates/core/terraform/azure-monitor folder and the required private DNS zones in file /templates/core/terraform/network/dns_zones.tf . Network security groups TRE Core Network security groups (NSG), and their security rules for TRE core resources are defined in /templates/core/terraform/network/network_security_groups.tf . Network security group Associated subnet(s) nsg-bastion-subnet AzureBastionSubnet nsg-app-gw AppGwSubnet nsg-default-rules ResourceProcessorSubnet , SharedSubnet , WebAppSubnet Workspaces Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The rules to manage and limit the traffic between the TRE Core VNET and Workspace VNETs are defined by the nsg-ws network security group: Inbound traffic from TRE Core VNET to workspace allowed for Azure Bastion (22, 3389) - All other inbound traffic from Core to workspace denied. Outbound traffic to SharedSubnet from Workspace allowed. Outbound traffic to Internet allowed on HTTPS port 443 (next hop Azure Firewall). All other outbound traffic denied. Each of these rules can be managed per workspace. Caution In Azure, traffic between subnets are allowed except explicitly denied.","title":"Network Architecture"},{"location":"azure-tre-overview/networking/#network-architecture","text":"The Trusted Research Environment (TRE) network topology is based on hub-spoke . The TRE Core VNET ( Azure Virtual Network ) is the central hub and each workspace is a spoke. Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The security rules are managed by nsg-ws network security group. See workspace network security groups (NSG) further down. The Core VNET is further divided into subnets. Subnet Description AzureBastionSubnet A dedicated subnet for Azure Bastion hosts. AppGwSubnet Subnet for Azure Application Gateway controlling ingress traffic. AzureFirewallSubnet Subnet for Azure Firewall controlling egress traffic. ResourceProcessorSubnet Subnet for VMSS used by the Composition Service to host Docker containers to execute Porter bundles that deploys Workspaces. WebAppSubnet Subnet for TRE API. SharedSubnet Shared Services subnet for all things shared by TRE Core and Workspaces. Such as Source Mirror Shared Service and Package Mirror Shared Service. All subnets (Core and Workspace subnets) have a default route which directs egress traffic to the Azure Firewall to ensure only explicitly allowed destinations on the Internet to be accessed. There are a couple of exceptions: AzureFirewallSubnet as it hosts the Azure Firewall which routes traffic to the Internet. AzureBastionSubnet as it hosts Azure Bastion which is the management jump box within the VNET with Internet access. AppGwSubnet as it hosts the Azure Application Gateway which has to be able to a ping the health endpoints e.g. TRE API.","title":"Network Architecture"},{"location":"azure-tre-overview/networking/#ingress-and-egress","text":"Ingress traffic from the Internet is only allowed through the Application Gateway, which forwards HTTPS (port 443) call to the TRE API in the WebAppSubnet . Egress traffic is routed through the Azure Firewall with a few exceptions and by default all ingress and egress traffic is denied except explicitly allowed. The explicitly allowed egress traffic is described here: Resource Processor TRE API Gitea Shared Service Nexus Shared Service","title":"Ingress and egress"},{"location":"azure-tre-overview/networking/#azure-monitor","text":"Azure Monitor resources are secured using Azure Monitor Private Link Scope (AMPLS) keeping all traffic inside the Microsoft Azure backbone network. The Azure Monitor resources and their network configuration is defined in /templates/core/terraform/azure-monitor folder and the required private DNS zones in file /templates/core/terraform/network/dns_zones.tf .","title":"Azure Monitor"},{"location":"azure-tre-overview/networking/#network-security-groups","text":"","title":"Network security groups"},{"location":"azure-tre-overview/networking/#tre-core","text":"Network security groups (NSG), and their security rules for TRE core resources are defined in /templates/core/terraform/network/network_security_groups.tf . Network security group Associated subnet(s) nsg-bastion-subnet AzureBastionSubnet nsg-app-gw AppGwSubnet nsg-default-rules ResourceProcessorSubnet , SharedSubnet , WebAppSubnet","title":"TRE Core"},{"location":"azure-tre-overview/networking/#workspaces","text":"Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The rules to manage and limit the traffic between the TRE Core VNET and Workspace VNETs are defined by the nsg-ws network security group: Inbound traffic from TRE Core VNET to workspace allowed for Azure Bastion (22, 3389) - All other inbound traffic from Core to workspace denied. Outbound traffic to SharedSubnet from Workspace allowed. Outbound traffic to Internet allowed on HTTPS port 443 (next hop Azure Firewall). All other outbound traffic denied. Each of these rules can be managed per workspace. Caution In Azure, traffic between subnets are allowed except explicitly denied.","title":"Workspaces"},{"location":"azure-tre-overview/user-roles/","text":"User roles The Azure TRE solution has 8 different user roles defined. The roles are modeled around a set of tasks for each role. The roles are not mutually exclusive, and one person can have multiple roles assigned to be able to carry out a broader set of tasks. Before you deploy a Trusted Research Environment based on the Azure TRE solution, you should consider your scenario and have an understanding of which of these roles that needs to be staffed. Role overview While we have defined 8 different user roles for the Azure TRE solution, not all of them are required in all scenarios. Three of the roles support role-based access control (RBAC) within the TRE. Role Key task TRE RBAC Azure administrator Deploy the TRE TRE administrator Administer the TRE \u2714 TRE workspace owner Own a workspace \u2714 Researcher Perform research on the data \u2714 TRE service integrator Integrate additional workspace services Azure TRE developer Extend the TRE OSS solution Data engineer Move data to and potentially from the TRE Information security officer Validate and sign-off TRE deployment Azure administrator Provisions the Azure TRE solution in an Azure subscription and performs tasks that require knowledge of Azure operations and has access to the Azure subscription. Example tasks: Provision Azure TRE solution instances. Second line support for TRE administrators, TRE workspace owners and Researchers when Azure TRE troubleshooting is required. Work with the data engineer to connect the Azure TRE with the data platform. Troubleshoot provisioning issues and failed deployments. Manage TRE administrator users. Manage data backups and restores. Update the Azure TRE instances. Configure log and metrics alerts. Expected skills: Azure administration and operations. Infrastructure as Code (Terraform, ARM, Git) PowerShell, Bash TRE administrator Day-to-day running and operations of the Azure TRE instance without touching Azure resources. Example tasks: Manage workspace owner users. Provision workspaces. Manage shared services e.g., available packages in package mirror shared service. Monitor workspace usage and billing. Set and manage quotas. Create and manage workspaces Expected skills: Limited or no Azure knowledge expected. TRE workspace owner Owns a specific workspace and has additional privileges than the researcher within the workspace. Is most likely also a Researcher . Example tasks: Manage Researcher users. Export data from workspace. Import data and make it available within the workspace. Enable services within the workspace. Monitor billing and usage of the workspace. Create and manage workspace services Expected skills: Limited or no Azure knowledge expected. Researcher Has access to one specific workspace and can use all the services provisioned within that workspace. Example tasks: Import software packages needed to conduct research (PyPi, Conda, Apt). Perform research using the services in the workspace. Create and manage user resources Expected skills: Python, R Git Linux TRE service integrator Integrates workspace service types with an Azure TRE instance. This involves extending the Azure Infrastructure as Code templates to make a workspace service available within an Azure TRE instance. Example tasks: Integrate a workspace service type with your Azure TRE instance. Implement Infrastructure as Code templates for new workspace service types. Expected skills: Infrastructure as Code (Terraform, ARM, Git) Python, C#, PowerShell, Bash Azure administration Azure TRE developer Software developer who contributes to the development of the Azure TRE solution. Example tasks: Modify the deployment service, API and other components of the Azure TRE solution. Contribute to the Azure TRE OSS solution. Expected skills: Infrastructure as Code (Terraform, ARM, Git) Python, C#, PowerShell, Bash Azure administration Data engineer Supporting role that is expected to build data movement pipelines between the data platform (not part of the TRE), and the TRE instance. Example tasks: Transfer data from the data platform to the TRE and potentially back. Create data movement and transformation pipelines. Expected skills: Python, Bash, Linux Azure Data Factory, Other ETL tools. Information Security Officer Needs to understand the security posture of the TRE to ensure that the organization is compliant with the information governance framework and additional relevant regulations. Example tasks: Use the Azure TRE documentation to understand the security posture of the TRE. Work with Azure administrator and TRE administrator to enforce the required security and privacy controls on the TRE. Commission penetration testing. Work with organization Information Governance committee to validate and sign-off Azure TRE deployment","title":"User Roles"},{"location":"azure-tre-overview/user-roles/#user-roles","text":"The Azure TRE solution has 8 different user roles defined. The roles are modeled around a set of tasks for each role. The roles are not mutually exclusive, and one person can have multiple roles assigned to be able to carry out a broader set of tasks. Before you deploy a Trusted Research Environment based on the Azure TRE solution, you should consider your scenario and have an understanding of which of these roles that needs to be staffed.","title":"User roles"},{"location":"azure-tre-overview/user-roles/#role-overview","text":"While we have defined 8 different user roles for the Azure TRE solution, not all of them are required in all scenarios. Three of the roles support role-based access control (RBAC) within the TRE. Role Key task TRE RBAC Azure administrator Deploy the TRE TRE administrator Administer the TRE \u2714 TRE workspace owner Own a workspace \u2714 Researcher Perform research on the data \u2714 TRE service integrator Integrate additional workspace services Azure TRE developer Extend the TRE OSS solution Data engineer Move data to and potentially from the TRE Information security officer Validate and sign-off TRE deployment","title":"Role overview"},{"location":"azure-tre-overview/user-roles/#azure-administrator","text":"Provisions the Azure TRE solution in an Azure subscription and performs tasks that require knowledge of Azure operations and has access to the Azure subscription. Example tasks: Provision Azure TRE solution instances. Second line support for TRE administrators, TRE workspace owners and Researchers when Azure TRE troubleshooting is required. Work with the data engineer to connect the Azure TRE with the data platform. Troubleshoot provisioning issues and failed deployments. Manage TRE administrator users. Manage data backups and restores. Update the Azure TRE instances. Configure log and metrics alerts. Expected skills: Azure administration and operations. Infrastructure as Code (Terraform, ARM, Git) PowerShell, Bash","title":"Azure administrator"},{"location":"azure-tre-overview/user-roles/#tre-administrator","text":"Day-to-day running and operations of the Azure TRE instance without touching Azure resources. Example tasks: Manage workspace owner users. Provision workspaces. Manage shared services e.g., available packages in package mirror shared service. Monitor workspace usage and billing. Set and manage quotas. Create and manage workspaces Expected skills: Limited or no Azure knowledge expected.","title":"TRE administrator"},{"location":"azure-tre-overview/user-roles/#tre-workspace-owner","text":"Owns a specific workspace and has additional privileges than the researcher within the workspace. Is most likely also a Researcher . Example tasks: Manage Researcher users. Export data from workspace. Import data and make it available within the workspace. Enable services within the workspace. Monitor billing and usage of the workspace. Create and manage workspace services Expected skills: Limited or no Azure knowledge expected.","title":"TRE workspace owner"},{"location":"azure-tre-overview/user-roles/#researcher","text":"Has access to one specific workspace and can use all the services provisioned within that workspace. Example tasks: Import software packages needed to conduct research (PyPi, Conda, Apt). Perform research using the services in the workspace. Create and manage user resources Expected skills: Python, R Git Linux","title":"Researcher"},{"location":"azure-tre-overview/user-roles/#tre-service-integrator","text":"Integrates workspace service types with an Azure TRE instance. This involves extending the Azure Infrastructure as Code templates to make a workspace service available within an Azure TRE instance. Example tasks: Integrate a workspace service type with your Azure TRE instance. Implement Infrastructure as Code templates for new workspace service types. Expected skills: Infrastructure as Code (Terraform, ARM, Git) Python, C#, PowerShell, Bash Azure administration","title":"TRE service integrator"},{"location":"azure-tre-overview/user-roles/#azure-tre-developer","text":"Software developer who contributes to the development of the Azure TRE solution. Example tasks: Modify the deployment service, API and other components of the Azure TRE solution. Contribute to the Azure TRE OSS solution. Expected skills: Infrastructure as Code (Terraform, ARM, Git) Python, C#, PowerShell, Bash Azure administration","title":"Azure TRE developer"},{"location":"azure-tre-overview/user-roles/#data-engineer","text":"Supporting role that is expected to build data movement pipelines between the data platform (not part of the TRE), and the TRE instance. Example tasks: Transfer data from the data platform to the TRE and potentially back. Create data movement and transformation pipelines. Expected skills: Python, Bash, Linux Azure Data Factory, Other ETL tools.","title":"Data engineer"},{"location":"azure-tre-overview/user-roles/#information-security-officer","text":"Needs to understand the security posture of the TRE to ensure that the organization is compliant with the information governance framework and additional relevant regulations. Example tasks: Use the Azure TRE documentation to understand the security posture of the TRE. Work with Azure administrator and TRE administrator to enforce the required security and privacy controls on the TRE. Commission penetration testing. Work with organization Information Governance committee to validate and sign-off Azure TRE deployment","title":"Information Security Officer"},{"location":"azure-tre-overview/shared-services/gitea/","text":"Gitea Shared Service As outbound access to public git repositories such as GitHub is often blocked a git mirror may be required. Gitea can be deployed as a shared service to offer this functionality. Documentation on Gitea can be found here: https://docs.gitea.io/ . Deploy To deploy set DEPLOY_GITEA=true in templates/core/.env Getting Started Connect to the Gitea admin console https://yourtreuri/gitea/ with the giteaadmin user. You can find the password in keyvault as gitea password . Network requirements Gitea needs to be able to access the following resource outside the Azure TRE VNET via explicitly allowed Service Tags or URLs. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Gitea container image, as it is located in Azure Container Registry. (www.)github.com Allows Gitea to mirror any repo on GitHub","title":"Gitea (Source Mirror)"},{"location":"azure-tre-overview/shared-services/gitea/#gitea-shared-service","text":"As outbound access to public git repositories such as GitHub is often blocked a git mirror may be required. Gitea can be deployed as a shared service to offer this functionality. Documentation on Gitea can be found here: https://docs.gitea.io/ .","title":"Gitea Shared Service"},{"location":"azure-tre-overview/shared-services/gitea/#deploy","text":"To deploy set DEPLOY_GITEA=true in templates/core/.env","title":"Deploy"},{"location":"azure-tre-overview/shared-services/gitea/#getting-started","text":"Connect to the Gitea admin console https://yourtreuri/gitea/ with the giteaadmin user. You can find the password in keyvault as gitea password .","title":"Getting Started"},{"location":"azure-tre-overview/shared-services/gitea/#network-requirements","text":"Gitea needs to be able to access the following resource outside the Azure TRE VNET via explicitly allowed Service Tags or URLs. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Gitea container image, as it is located in Azure Container Registry. (www.)github.com Allows Gitea to mirror any repo on GitHub","title":"Network requirements"},{"location":"azure-tre-overview/shared-services/nexus/","text":"Nexus Shared Service Sonatype Nexus (RepoManager) allows users in workspaces to access external software packages securely. Documentation on Nexus can be found here: https://help.sonatype.com/repomanager3/ . Deploy To deploy set DEPLOY_NEXUS=true in templates/core/.env . Nexus will be deployed as part of the main TRE terraform deployment. A configuration script needs to be run once the deployment is done. The script will: Fetch the Nexus generated password from storage account. Reset the default password and set a new one. Store the new password in Key Vault under 'nexus- -admin-password' Create an anonymous default PyPI proxy repository Setup and usage A TRE Administrator can access Nexus though the admin jumpbox provisioned as part of the TRE deployment. The credentials for the jumpbox are located in the KeyVault under \"vm- -jumpbox-admin-credentials\" A researcher can access Nexus from within the workspace by using the internal Nexus URL of: https://nexus- .azurewebsites.net/ To fetch Python packages from the PyPI proxy, a researcher can use pip install while specifying the proxy server: pip install packagename --index-url https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple Network requirements Nexus Shared Service requires access to resources outside of the Azure TRE VNET. These are set as part of the firewall provisioning pipeline via explicit allow on Service Tags or URLs. Notice that since Nexus Shared Service is running on an App Service, the outgoing exceptions are made for the calls coming out of the Web App Subnet. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Nexus container image, as it is located in Azure Container Registry. pypi.org Enables Nexus to \"proxy\" python packages to use inside of workspaces","title":"Nexus (Package Mirror)"},{"location":"azure-tre-overview/shared-services/nexus/#nexus-shared-service","text":"Sonatype Nexus (RepoManager) allows users in workspaces to access external software packages securely. Documentation on Nexus can be found here: https://help.sonatype.com/repomanager3/ .","title":"Nexus Shared Service"},{"location":"azure-tre-overview/shared-services/nexus/#deploy","text":"To deploy set DEPLOY_NEXUS=true in templates/core/.env . Nexus will be deployed as part of the main TRE terraform deployment. A configuration script needs to be run once the deployment is done. The script will: Fetch the Nexus generated password from storage account. Reset the default password and set a new one. Store the new password in Key Vault under 'nexus- -admin-password' Create an anonymous default PyPI proxy repository","title":"Deploy"},{"location":"azure-tre-overview/shared-services/nexus/#setup-and-usage","text":"A TRE Administrator can access Nexus though the admin jumpbox provisioned as part of the TRE deployment. The credentials for the jumpbox are located in the KeyVault under \"vm- -jumpbox-admin-credentials\" A researcher can access Nexus from within the workspace by using the internal Nexus URL of: https://nexus- .azurewebsites.net/ To fetch Python packages from the PyPI proxy, a researcher can use pip install while specifying the proxy server: pip install packagename --index-url https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple","title":"Setup and usage"},{"location":"azure-tre-overview/shared-services/nexus/#network-requirements","text":"Nexus Shared Service requires access to resources outside of the Azure TRE VNET. These are set as part of the firewall provisioning pipeline via explicit allow on Service Tags or URLs. Notice that since Nexus Shared Service is running on an App Service, the outgoing exceptions are made for the calls coming out of the Web App Subnet. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Nexus container image, as it is located in Azure Container Registry. pypi.org Enables Nexus to \"proxy\" python packages to use inside of workspaces","title":"Network requirements"},{"location":"tre-admins/auth/","text":"Authentication and authorization Azure Active Directory (AAD) is the backbone of Authentication and Authorization in the TRE. It holds the identities of all TRE/workspace users, including administrators, and connects the identities with app registrations defining the privileges per user roles. App registrations App registrations (represented by service principals) define the privileges enabling access to the TRE system (e.g., API ) as well as the workspaces. You can create the app registrations needed for the API by running the /scripts/aad-app-reg.sh script. Alternatively, you can create the app registrations manually via the Azure Portal . The requirements are listed below. Note Additional app registrations are required to run the E2E tests, and also to create workspaces - these are not configured by the aad-app-reg.sh script. Find information below on how to set these up. Some of the applications require admin consent to allow them to validate users against the AAD. Check the Microsoft Docs on Configure the admin consent workflow on how to request admin consent and handle admin consent requests. App registration script The /scripts/aad-app-reg.sh script automatically sets up the app registrations with the required permissions to run Azure TRE. It will create and configure the two main app registrations: TRE API and TRE Swagger UI . Example on how to run the script: ./aad-app-reg.sh \\ --name <Prefix of the app registration names e.g., TRE> \\ --swaggerui-redirecturl https://<TRE ID>.<Azure location>.cloudapp.azure.com/api/docs/oauth2-redirect \\ --admin-consent Argument Description --name The prefix of the name of the app registrations. TRE will give you TRE API and TRE Swagger UI . --swaggerui-redirecturl The reply URL for the Swagger UI app. Use the values of the environment variables TRE_ID and LOCATION in the URL. Reply URL for the localhost, http://localhost:8000/api/docs/oauth2-redirect , will be added by default. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. Caution The script will create an app password (client secret) for the TRE API app; make sure to take note of it in the script output as it is only shown once. In case the secret is lost, the script, when run again, can reset it and display the new one. In addition to the TRE API and TRE Swagger UI app registrations, the aad-app-reg.sh script can also be used to create an app registration that can be used for authenticating against the API from automation (for example, for registering bundles via CI/CD). To do this, add the --automation-account switch as shown in the following command: ./aad-app-reg.sh \\ --name <Prefix of the app registration names e.g., TRE> \\ --swaggerui-redirecturl https://<TRE ID>.<Azure location>.cloudapp.azure.com/api/docs/oauth2-redirect \\ --automation-account \\ --admin-consent TRE API The TRE API app registration defines the permissions, scopes and app roles for API users to authenticate and authorize API calls. API permissions - TRE API API/permission name Type Description Admin consent required Status TRE usage Microsoft Graph/Directory.Read.All ( https://graph.microsoft.com/Directory.Read.All ) Application* Allows the app to read data in your organization's directory, such as users, groups and apps, without a signed-in user. Yes Granted for [directory name] Used e.g., to retrieve app registration details, user associated app roles etc. Microsoft Graph/User.Read.All ( https://graph.microsoft.com/User.Read.All ) Application* Allows the app to read user profiles without a signed in user. Yes Granted for [directory name] Reading user role assignments to check that the user has permissions to execute an action e.g., to view workspaces. See /api_app/services/aad_authentication.py . *) See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details. Scopes - TRE API api://<Application (client) ID>/ user_impersonation - Allow the app to access the TRE API on behalf of the signed-in user App roles - TRE API Display name Description Allowed member types Value TRE Administrators Provides resource administrator access to the TRE. Users/Groups,Applications TREAdmin TRE Users Provides access to the TRE application. Users/Groups,Applications TREUser Authentication - TRE API The TRE API app registration requires no redirect URLs defined or anything else for that matter. From a security standpoint it should be noted that public client flows should not be allowed. As the identity of the client application cannot be verified (see the image below taken from app registration authentication blade in Azure Portal). TRE Swagger UI TRE Swagger UI app registration: Controls the access to the Swagger UI of the TRE API Has no scopes or app roles defined API permissions - TRE Swagger UI API/permission name Type Description Admin consent required Status Microsoft Graph/offline_access ( https://graph.microsoft.com/offline_access ) Delegated* Allows the app to see and update the data you gave it access to, even when users are not currently using the app. No Granted for [directory name] Microsoft Graph/openid ( https://graph.microsoft.com/openid ) Delegated* Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. No Granted for [directory name] TRE API/user_impersonation ( api://<TRE API Application (client) ID>/user_impersonation ) Delegated* See TRE API app registration scopes . No Granted for [directory name] *) See the difference between delegated and application permission types. Authentication - TRE Swagger UI Redirect URLs: https://<TRE ID>.<Azure location>.cloudapp.azure.com/docs/oauth2-redirect http://localhost:8000/docs/oauth2-redirect - For local testing TRE e2e test The TRE e2e test app registration is used to authorize end-to-end test scenarios. It has no scopes or app roles defined. Note This app registration is only needed and used for testing As of writing this, there is no automated way provided for creating the TRE e2e test app registration, so it needs to be created manually. API permissions - TRE e2e test API/permission name Type Description Admin consent required Microsoft Graph/openid ( https://graph.microsoft.com/openid ) Delegated Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. No Microsoft Graph/User.Read ( https://graph.microsoft.com/User.Read ) Delegated Allows users to sign-in to the app, and allows the app to read the profile of signed-in users. It also allows the app to read basic company information of signed-in users. No .user_impersonation Delegated Allow the app access the TRE API on behalf of the signed-in user No Authentication - TRE e2e test Define Redirect URLs: In the TRE e2e test app registration go to Authentication -> Add platform -> Select Mobile & Desktop and add: https://login.microsoftonline.com/common/oauth2/nativeclient msal<TRE e2e test app registration application (client) ID>://auth Allow public client flows (see the image below). This enables the end-to-end tests to use a username and password combination to authenticate. Warning OAuth 2.0 Public client flow cannot verify the the client application identity, it should only be enabled if needed. End-to-end test user The end-to-end test authentication and authorization is done via a dummy user, using its username and password, dedicated just for running the tests. The user is linked to the application (app registration) the same way as any other users (see Enabling users ). The end-to-end test should be added to TRE Administrator role exposed by the TRE API application, and to the Owners role exposed by the Workspaces application. Workspaces Access to workspaces is also controlled using app registrations - one per workspace. The configuration of the app registration depends on the nature of the workspace, but this section covers the typical minimum settings. Caution The app registration for a workspace is not created by the API . One needs to be present (created manually) before using the API to provision a new workspace. Authentication - Workspaces Same as TRE API . API permissions - Workspaces API/permission name Type Description Admin consent required Microsoft Graph/User.Read ( https://graph.microsoft.com/User.Read ) Delegated Allows users to sign-in to the app, and allows the app to read the profile of signed-in users. It also allows the app to read basic company information of signed-in users. No Workspace API/user_impersonation ( api://<Workspace API Application (client) ID>/user_impersonation ) Delegated* Allows the app to access the workspace API on behalf of the user No App roles Display name Description Allowed member types Value Owners Provides ownership access to workspace. Users/Groups WorkspaceOwner Researchers Provides access to workspace. Users/Groups WorkspaceResearcher Enabling users For a user to gain access to the system, they have to: Have an identity in Azure AD Be linked with an app registration and assigned a role When these requirements are met, the user can sign-in using their credentials and use their privileges to use the API, login to workspace environment etc. based on their specific roles. The users can also be linked via the Enterprise application view:","title":"Authentication and Authorization"},{"location":"tre-admins/auth/#authentication-and-authorization","text":"Azure Active Directory (AAD) is the backbone of Authentication and Authorization in the TRE. It holds the identities of all TRE/workspace users, including administrators, and connects the identities with app registrations defining the privileges per user roles.","title":"Authentication and authorization"},{"location":"tre-admins/auth/#app-registrations","text":"App registrations (represented by service principals) define the privileges enabling access to the TRE system (e.g., API ) as well as the workspaces. You can create the app registrations needed for the API by running the /scripts/aad-app-reg.sh script. Alternatively, you can create the app registrations manually via the Azure Portal . The requirements are listed below. Note Additional app registrations are required to run the E2E tests, and also to create workspaces - these are not configured by the aad-app-reg.sh script. Find information below on how to set these up. Some of the applications require admin consent to allow them to validate users against the AAD. Check the Microsoft Docs on Configure the admin consent workflow on how to request admin consent and handle admin consent requests.","title":"App registrations"},{"location":"tre-admins/auth/#app-registration-script","text":"The /scripts/aad-app-reg.sh script automatically sets up the app registrations with the required permissions to run Azure TRE. It will create and configure the two main app registrations: TRE API and TRE Swagger UI . Example on how to run the script: ./aad-app-reg.sh \\ --name <Prefix of the app registration names e.g., TRE> \\ --swaggerui-redirecturl https://<TRE ID>.<Azure location>.cloudapp.azure.com/api/docs/oauth2-redirect \\ --admin-consent Argument Description --name The prefix of the name of the app registrations. TRE will give you TRE API and TRE Swagger UI . --swaggerui-redirecturl The reply URL for the Swagger UI app. Use the values of the environment variables TRE_ID and LOCATION in the URL. Reply URL for the localhost, http://localhost:8000/api/docs/oauth2-redirect , will be added by default. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. Caution The script will create an app password (client secret) for the TRE API app; make sure to take note of it in the script output as it is only shown once. In case the secret is lost, the script, when run again, can reset it and display the new one. In addition to the TRE API and TRE Swagger UI app registrations, the aad-app-reg.sh script can also be used to create an app registration that can be used for authenticating against the API from automation (for example, for registering bundles via CI/CD). To do this, add the --automation-account switch as shown in the following command: ./aad-app-reg.sh \\ --name <Prefix of the app registration names e.g., TRE> \\ --swaggerui-redirecturl https://<TRE ID>.<Azure location>.cloudapp.azure.com/api/docs/oauth2-redirect \\ --automation-account \\ --admin-consent","title":"App registration script"},{"location":"tre-admins/auth/#tre-api","text":"The TRE API app registration defines the permissions, scopes and app roles for API users to authenticate and authorize API calls.","title":"TRE API"},{"location":"tre-admins/auth/#api-permissions-tre-api","text":"API/permission name Type Description Admin consent required Status TRE usage Microsoft Graph/Directory.Read.All ( https://graph.microsoft.com/Directory.Read.All ) Application* Allows the app to read data in your organization's directory, such as users, groups and apps, without a signed-in user. Yes Granted for [directory name] Used e.g., to retrieve app registration details, user associated app roles etc. Microsoft Graph/User.Read.All ( https://graph.microsoft.com/User.Read.All ) Application* Allows the app to read user profiles without a signed in user. Yes Granted for [directory name] Reading user role assignments to check that the user has permissions to execute an action e.g., to view workspaces. See /api_app/services/aad_authentication.py . *) See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details.","title":"API permissions - TRE API"},{"location":"tre-admins/auth/#scopes-tre-api","text":"api://<Application (client) ID>/ user_impersonation - Allow the app to access the TRE API on behalf of the signed-in user","title":"Scopes - TRE API"},{"location":"tre-admins/auth/#app-roles-tre-api","text":"Display name Description Allowed member types Value TRE Administrators Provides resource administrator access to the TRE. Users/Groups,Applications TREAdmin TRE Users Provides access to the TRE application. Users/Groups,Applications TREUser","title":"App roles - TRE API"},{"location":"tre-admins/auth/#authentication-tre-api","text":"The TRE API app registration requires no redirect URLs defined or anything else for that matter. From a security standpoint it should be noted that public client flows should not be allowed. As the identity of the client application cannot be verified (see the image below taken from app registration authentication blade in Azure Portal).","title":"Authentication - TRE API"},{"location":"tre-admins/auth/#tre-swagger-ui","text":"TRE Swagger UI app registration: Controls the access to the Swagger UI of the TRE API Has no scopes or app roles defined","title":"TRE Swagger UI"},{"location":"tre-admins/auth/#api-permissions-tre-swagger-ui","text":"API/permission name Type Description Admin consent required Status Microsoft Graph/offline_access ( https://graph.microsoft.com/offline_access ) Delegated* Allows the app to see and update the data you gave it access to, even when users are not currently using the app. No Granted for [directory name] Microsoft Graph/openid ( https://graph.microsoft.com/openid ) Delegated* Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. No Granted for [directory name] TRE API/user_impersonation ( api://<TRE API Application (client) ID>/user_impersonation ) Delegated* See TRE API app registration scopes . No Granted for [directory name] *) See the difference between delegated and application permission types.","title":"API permissions - TRE Swagger UI"},{"location":"tre-admins/auth/#authentication-tre-swagger-ui","text":"Redirect URLs: https://<TRE ID>.<Azure location>.cloudapp.azure.com/docs/oauth2-redirect http://localhost:8000/docs/oauth2-redirect - For local testing","title":"Authentication - TRE Swagger UI"},{"location":"tre-admins/auth/#tre-e2e-test","text":"The TRE e2e test app registration is used to authorize end-to-end test scenarios. It has no scopes or app roles defined. Note This app registration is only needed and used for testing As of writing this, there is no automated way provided for creating the TRE e2e test app registration, so it needs to be created manually.","title":"TRE e2e test"},{"location":"tre-admins/auth/#api-permissions-tre-e2e-test","text":"API/permission name Type Description Admin consent required Microsoft Graph/openid ( https://graph.microsoft.com/openid ) Delegated Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. No Microsoft Graph/User.Read ( https://graph.microsoft.com/User.Read ) Delegated Allows users to sign-in to the app, and allows the app to read the profile of signed-in users. It also allows the app to read basic company information of signed-in users. No .user_impersonation Delegated Allow the app access the TRE API on behalf of the signed-in user No","title":"API permissions - TRE e2e test"},{"location":"tre-admins/auth/#authentication-tre-e2e-test","text":"Define Redirect URLs: In the TRE e2e test app registration go to Authentication -> Add platform -> Select Mobile & Desktop and add: https://login.microsoftonline.com/common/oauth2/nativeclient msal<TRE e2e test app registration application (client) ID>://auth Allow public client flows (see the image below). This enables the end-to-end tests to use a username and password combination to authenticate. Warning OAuth 2.0 Public client flow cannot verify the the client application identity, it should only be enabled if needed.","title":"Authentication - TRE e2e test"},{"location":"tre-admins/auth/#end-to-end-test-user","text":"The end-to-end test authentication and authorization is done via a dummy user, using its username and password, dedicated just for running the tests. The user is linked to the application (app registration) the same way as any other users (see Enabling users ). The end-to-end test should be added to TRE Administrator role exposed by the TRE API application, and to the Owners role exposed by the Workspaces application.","title":"End-to-end test user"},{"location":"tre-admins/auth/#workspaces","text":"Access to workspaces is also controlled using app registrations - one per workspace. The configuration of the app registration depends on the nature of the workspace, but this section covers the typical minimum settings. Caution The app registration for a workspace is not created by the API . One needs to be present (created manually) before using the API to provision a new workspace.","title":"Workspaces"},{"location":"tre-admins/auth/#authentication-workspaces","text":"Same as TRE API .","title":"Authentication - Workspaces"},{"location":"tre-admins/auth/#api-permissions-workspaces","text":"API/permission name Type Description Admin consent required Microsoft Graph/User.Read ( https://graph.microsoft.com/User.Read ) Delegated Allows users to sign-in to the app, and allows the app to read the profile of signed-in users. It also allows the app to read basic company information of signed-in users. No Workspace API/user_impersonation ( api://<Workspace API Application (client) ID>/user_impersonation ) Delegated* Allows the app to access the workspace API on behalf of the user No","title":"API permissions - Workspaces"},{"location":"tre-admins/auth/#app-roles","text":"Display name Description Allowed member types Value Owners Provides ownership access to workspace. Users/Groups WorkspaceOwner Researchers Provides access to workspace. Users/Groups WorkspaceResearcher","title":"App roles"},{"location":"tre-admins/auth/#enabling-users","text":"For a user to gain access to the system, they have to: Have an identity in Azure AD Be linked with an app registration and assigned a role When these requirements are met, the user can sign-in using their credentials and use their privileges to use the API, login to workspace environment etc. based on their specific roles. The users can also be linked via the Enterprise application view:","title":"Enabling users"},{"location":"tre-admins/environment-variables/","text":"Environment variables Info The .tfvars file is intentionally not used. The .env file format is easier to parse, meaning we can use the values for bash scripts and other purposes. For shared management resources in /devops/.env Environment variable name Description LOCATION The Azure location (region) for all resources. MGMT_RESOURCE_GROUP_NAME The shared resource group for all management resources, including the storage account. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. TERRAFORM_STATE_CONTAINER_NAME The name of the blob container to hold the Terraform state Default value is tfstate . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. ARM_SUBSCRIPTION_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The Azure subscription ID for all resources. ARM_CLIENT_ID Optional for manual deployment without logged-in credentials. The client whose azure identity will be used to deploy the solution. ARM_CLIENT_SECRET Optional for manual deployment without logged-in credentials. The password of the client defined in ARM_CLIENT_ID . ARM_TENANT_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The AAD tenant of the client defined in ARM_CLIENT_ID . DEBUG If set to \"true\" disables purge protection of keyvault. For Azure TRE instance in /templates/core/.env Environment variable name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of mytre-dev will result in a resource group name for Azure TRE instance of rg-mytre-dev . This must be less than 12 characters. Allowed characters: Alphanumeric, underscores, and hyphens. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 SWAGGER_UI_CLIENT_ID Generated when following pre-deployment steps guide. Client ID for swagger client to make requests. AAD_TENANT_ID Generated when following pre-deployment steps guide. Tenant id against which auth is performed. API_CLIENT_ID Generated when following pre-deployment steps guide. Client id of the \"TRE API\". API_CLIENT_SECRET Generated when following pre-deployment steps guide. Client secret of the \"TRE API\". DEPLOY_GITEA If set to false disables deployment of the Gitea shared service . DEPLOY_NEXUS If set to false disables deployment of the Nexus shared service .","title":"Environment Variables"},{"location":"tre-admins/environment-variables/#environment-variables","text":"Info The .tfvars file is intentionally not used. The .env file format is easier to parse, meaning we can use the values for bash scripts and other purposes.","title":"Environment variables"},{"location":"tre-admins/environment-variables/#for-shared-management-resources-in-devopsenv","text":"Environment variable name Description LOCATION The Azure location (region) for all resources. MGMT_RESOURCE_GROUP_NAME The shared resource group for all management resources, including the storage account. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. TERRAFORM_STATE_CONTAINER_NAME The name of the blob container to hold the Terraform state Default value is tfstate . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. ARM_SUBSCRIPTION_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The Azure subscription ID for all resources. ARM_CLIENT_ID Optional for manual deployment without logged-in credentials. The client whose azure identity will be used to deploy the solution. ARM_CLIENT_SECRET Optional for manual deployment without logged-in credentials. The password of the client defined in ARM_CLIENT_ID . ARM_TENANT_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The AAD tenant of the client defined in ARM_CLIENT_ID . DEBUG If set to \"true\" disables purge protection of keyvault.","title":"For shared management resources in /devops/.env"},{"location":"tre-admins/environment-variables/#for-azure-tre-instance-in-templatescoreenv","text":"Environment variable name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of mytre-dev will result in a resource group name for Azure TRE instance of rg-mytre-dev . This must be less than 12 characters. Allowed characters: Alphanumeric, underscores, and hyphens. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 SWAGGER_UI_CLIENT_ID Generated when following pre-deployment steps guide. Client ID for swagger client to make requests. AAD_TENANT_ID Generated when following pre-deployment steps guide. Tenant id against which auth is performed. API_CLIENT_ID Generated when following pre-deployment steps guide. Client id of the \"TRE API\". API_CLIENT_SECRET Generated when following pre-deployment steps guide. Client secret of the \"TRE API\". DEPLOY_GITEA If set to false disables deployment of the Gitea shared service . DEPLOY_NEXUS If set to false disables deployment of the Nexus shared service .","title":"For Azure TRE instance in /templates/core/.env"},{"location":"tre-admins/registering-templates/","text":"Registering Templates To enable users to deploy Workspaces, Workspace Services or User Resources, we need to register their Templates using the API. Porter Bundles Templates are encapsulated in Porter bundles. Porter bundles can either be registered interactively using the Swagger UI or automatically using the /devops/scripts/publish_register_bundle.sh script (useful in CI/CD scenarios). This script can also be used to generate the payload required by the API without actually calling the API. It carries out the following actions: Publishes the bundle to the Azure Container Registry specified. Extracts the parameters from the bundle using porter explain . Registration using Swagger UI Build the porter bundle porter build Use the utility script to generate the payload. The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ ../../../devops/scripts/publish_register_bundle.sh -r <acr_name> -i -t workspace Copy the resulting JSON payload. Navigate to the Swagger UI at /api/docs Log into the Swagger UI using Authorize Click Try it out on the POST /api/workspace-templates operation: Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. Verify the template registration using the GET operation on /api/workspace-templates . The name of the template should now be listed. Registration using script To use the script to automatically register the template, you must create a user that does not require an interactive login per the e2e test user documentation here . The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ Usage: ../../../devops/scripts/publish_register_bundle.sh [-u --tre_url] [-c --current] [-i --insecure] Options: -r, --acr-name Azure Container Registry Name -t, --bundle-type Bundle type, workspace -c, --current: Make this the currently deployed version of this template -i, --insecure: Bypass SSL certificate checks -u, --tre_url: URL for the TRE (required for automatic registration) -a, --access-token Azure access token to automatically post to the API (required for automatic registration) In addition to generating the payload, the script posts the payload to the /api/workspace-templates endpoint. Once registered the template can be retrieved by a GET operation on /api/workspace-templates . Tip Follow the same procedure to register workspace service templates and user resource templates","title":"Registering Templates"},{"location":"tre-admins/registering-templates/#registering-templates","text":"To enable users to deploy Workspaces, Workspace Services or User Resources, we need to register their Templates using the API.","title":"Registering Templates"},{"location":"tre-admins/registering-templates/#porter-bundles","text":"Templates are encapsulated in Porter bundles. Porter bundles can either be registered interactively using the Swagger UI or automatically using the /devops/scripts/publish_register_bundle.sh script (useful in CI/CD scenarios). This script can also be used to generate the payload required by the API without actually calling the API. It carries out the following actions: Publishes the bundle to the Azure Container Registry specified. Extracts the parameters from the bundle using porter explain .","title":"Porter Bundles"},{"location":"tre-admins/registering-templates/#registration-using-swagger-ui","text":"Build the porter bundle porter build Use the utility script to generate the payload. The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ ../../../devops/scripts/publish_register_bundle.sh -r <acr_name> -i -t workspace Copy the resulting JSON payload. Navigate to the Swagger UI at /api/docs Log into the Swagger UI using Authorize Click Try it out on the POST /api/workspace-templates operation: Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. Verify the template registration using the GET operation on /api/workspace-templates . The name of the template should now be listed.","title":"Registration using Swagger UI"},{"location":"tre-admins/registering-templates/#registration-using-script","text":"To use the script to automatically register the template, you must create a user that does not require an interactive login per the e2e test user documentation here . The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ Usage: ../../../devops/scripts/publish_register_bundle.sh [-u --tre_url] [-c --current] [-i --insecure] Options: -r, --acr-name Azure Container Registry Name -t, --bundle-type Bundle type, workspace -c, --current: Make this the currently deployed version of this template -i, --insecure: Bypass SSL certificate checks -u, --tre_url: URL for the TRE (required for automatic registration) -a, --access-token Azure access token to automatically post to the API (required for automatic registration) In addition to generating the payload, the script posts the payload to the /api/workspace-templates endpoint. Once registered the template can be retrieved by a GET operation on /api/workspace-templates . Tip Follow the same procedure to register workspace service templates and user resource templates","title":"Registration using script"},{"location":"tre-admins/troubleshooting-guide/","text":"Operations Debugging and Troubleshooting guide This guide explains how to go about finding the root cause of why a workspace resource might not have been deployed. The steps listed below should be followed in order as that is how the message also flows in the system. Enabling DEBUG mode on the API The API is by default configured to not show detailed error messages and stack trace when an error occurs. This is done to prevent leaking internal state to the outside world and to minimize information which an attacker could use against the deployed instance. However, you can enable debugging, by setting DEBUG=true in the configuration settings of the API using Azure portal. Go to App Service for the API and select Settings > Configuration . Click New Application Setting . in the new dialog box set Name=DEBUG and Value=true With debugging enabled, when an error occurs at the API level it will display a detailed error message, which should help in understanding why the payload was not accepted. API logs using deployment center Check that the version you are debugging/troubleshooting is the same one deployed on the App Service. You can check this in Deployment Center, or follow the logs as generated by the container in the logs tabs. Checking the Service Bus If the message payload is accepted by the API, and a workspace_id is generated, you should be able to track the progress of the deployment using GET /api/workspaces/{workspace_id} Initially the status is always reported as: { \"deployment\" : { \"status\" : \"not_deployed\" , \"message\" : \"This resource has not yet been deployed\" } } This should eventually change as the message flows through the system. If the message remains at this stage, you should first verify that the message arrived in the service bus. In the Azure portal: Select the Service Bus from deployed resources and click Entities > Queues > workspacequeue . Select the Service Bus Explorer and the Peek tab to check for hanging messages. Checking the logs in App Insights Every component of TRE should send their trace logs to App Insights logging backend, and you should be able to see the process flow by using a suitable query. Note Traces take time to appear so be patient. Go to the deployed app insights instance and select Monitoring > Logs where you can run the following example query to get the logs for a specific deployment. let tracking_id=\"<workspace_id>\"; traces | where message contains tracking_id or operation_Id == tracking_id | sort by timestamp desc For a successful deployment you should see the last message (at the top since the order is timestamp descending) something like Received deployment status update message with correlation ID 28fcf096-6962-498b-9d2e-16d38dc6b7f6: {'id': '28fcf096-6962-498b-9d2e-16d38dc6b7f6', 'status': 'deployed', 'message': 'cse-msr-dev-b7f6: Workspace was deployed successfully...'} It should also be evident from the message flow where the current processing is stuck or failed. Failed deployment status should also be available in the GET /api/workspaces/{workspace_id} and this is just another way to confirm it. Checking the Virtual Machine Scale Set (VMSS) instance running resource processor If you see messages hanging in the service bus queue then the resource processor is not up and running. Verify that the VMSS instance is up and healthy. The processor runs in a VNET, and you cannot connect to it directly. Connect to the instance using Bastion. Bastion is already deployed, and you can use the username adminuser . The password is stored in the keyvault under the secret resource-processor-vmss-password Info You cannot see secrets unless you are added to a suitable access policy for the Key Vault. After logging in you should check the status of cloud-init which is used to bootstrap the machine with docker and start the processor. Log files for cloud init are: /var/log/cloud-init.log /var/log/cloud-init-output.log If the Docker container is pulled as shown in logs then the resource processor should start. Check the status of the container using docker ps If you see nothing (and the container was pulled) then the processor has either not started yet or it has crashed. Check the status of all Docker processes using docker ps -a which should show you if the container terminated prematurely. Get the logs from the container using docker logs <container_id> command. To start a processor container manually: Find the runner_image:tag by running docker ps Execute the following command from the root (/) of the file system docker run -v /var/run/docker.sock:/var/run/docker.sock --env-file .env --name resource_processor_vmss_porter_debug [runner_image:tag] Info All logs from the resource processor should also be transferred to the App Insights instance, so it is not necessary to follow the progress by logging into the instance. Logging into the instance and starting a container manually however, is helpful in live debugging. Updating the running container If you start a container manually you will probably want to install software, for example, an editor. However, the firewall blocks all ingress traffic, so you cannot run sudo apt update . You need to add an override rule in the firewall to allow the traffic. Caution Remember to remove this rule when debugging is done.","title":"Troubleshooting Guide"},{"location":"tre-admins/troubleshooting-guide/#operations-debugging-and-troubleshooting-guide","text":"This guide explains how to go about finding the root cause of why a workspace resource might not have been deployed. The steps listed below should be followed in order as that is how the message also flows in the system.","title":"Operations Debugging and Troubleshooting guide"},{"location":"tre-admins/troubleshooting-guide/#enabling-debug-mode-on-the-api","text":"The API is by default configured to not show detailed error messages and stack trace when an error occurs. This is done to prevent leaking internal state to the outside world and to minimize information which an attacker could use against the deployed instance. However, you can enable debugging, by setting DEBUG=true in the configuration settings of the API using Azure portal. Go to App Service for the API and select Settings > Configuration . Click New Application Setting . in the new dialog box set Name=DEBUG and Value=true With debugging enabled, when an error occurs at the API level it will display a detailed error message, which should help in understanding why the payload was not accepted.","title":"Enabling DEBUG mode on the API"},{"location":"tre-admins/troubleshooting-guide/#api-logs-using-deployment-center","text":"Check that the version you are debugging/troubleshooting is the same one deployed on the App Service. You can check this in Deployment Center, or follow the logs as generated by the container in the logs tabs.","title":"API logs using deployment center"},{"location":"tre-admins/troubleshooting-guide/#checking-the-service-bus","text":"If the message payload is accepted by the API, and a workspace_id is generated, you should be able to track the progress of the deployment using GET /api/workspaces/{workspace_id} Initially the status is always reported as: { \"deployment\" : { \"status\" : \"not_deployed\" , \"message\" : \"This resource has not yet been deployed\" } } This should eventually change as the message flows through the system. If the message remains at this stage, you should first verify that the message arrived in the service bus. In the Azure portal: Select the Service Bus from deployed resources and click Entities > Queues > workspacequeue . Select the Service Bus Explorer and the Peek tab to check for hanging messages.","title":"Checking the Service Bus"},{"location":"tre-admins/troubleshooting-guide/#checking-the-logs-in-app-insights","text":"Every component of TRE should send their trace logs to App Insights logging backend, and you should be able to see the process flow by using a suitable query. Note Traces take time to appear so be patient. Go to the deployed app insights instance and select Monitoring > Logs where you can run the following example query to get the logs for a specific deployment. let tracking_id=\"<workspace_id>\"; traces | where message contains tracking_id or operation_Id == tracking_id | sort by timestamp desc For a successful deployment you should see the last message (at the top since the order is timestamp descending) something like Received deployment status update message with correlation ID 28fcf096-6962-498b-9d2e-16d38dc6b7f6: {'id': '28fcf096-6962-498b-9d2e-16d38dc6b7f6', 'status': 'deployed', 'message': 'cse-msr-dev-b7f6: Workspace was deployed successfully...'} It should also be evident from the message flow where the current processing is stuck or failed. Failed deployment status should also be available in the GET /api/workspaces/{workspace_id} and this is just another way to confirm it.","title":"Checking the logs in App Insights"},{"location":"tre-admins/troubleshooting-guide/#checking-the-virtual-machine-scale-set-vmss-instance-running-resource-processor","text":"If you see messages hanging in the service bus queue then the resource processor is not up and running. Verify that the VMSS instance is up and healthy. The processor runs in a VNET, and you cannot connect to it directly. Connect to the instance using Bastion. Bastion is already deployed, and you can use the username adminuser . The password is stored in the keyvault under the secret resource-processor-vmss-password Info You cannot see secrets unless you are added to a suitable access policy for the Key Vault. After logging in you should check the status of cloud-init which is used to bootstrap the machine with docker and start the processor. Log files for cloud init are: /var/log/cloud-init.log /var/log/cloud-init-output.log If the Docker container is pulled as shown in logs then the resource processor should start. Check the status of the container using docker ps If you see nothing (and the container was pulled) then the processor has either not started yet or it has crashed. Check the status of all Docker processes using docker ps -a which should show you if the container terminated prematurely. Get the logs from the container using docker logs <container_id> command. To start a processor container manually: Find the runner_image:tag by running docker ps Execute the following command from the root (/) of the file system docker run -v /var/run/docker.sock:/var/run/docker.sock --env-file .env --name resource_processor_vmss_porter_debug [runner_image:tag] Info All logs from the resource processor should also be transferred to the App Insights instance, so it is not necessary to follow the progress by logging into the instance. Logging into the instance and starting a container manually however, is helpful in live debugging.","title":"Checking the Virtual Machine Scale Set (VMSS) instance running resource processor"},{"location":"tre-admins/troubleshooting-guide/#updating-the-running-container","text":"If you start a container manually you will probably want to install software, for example, an editor. However, the firewall blocks all ingress traffic, so you cannot run sudo apt update . You need to add an override rule in the firewall to allow the traffic. Caution Remember to remove this rule when debugging is done.","title":"Updating the running container"},{"location":"tre-admins/setup-instructions/configuring-shared-services/","text":"Configuring Shared Services Complete the configuration of the shared services (Nexus and Gitea) from inside of the TRE environment. Prepare the admin jumpbox Sign in to the admin jumpbox provisioned as part of the TRE deployment using Bastion. The credentials for the jumpbox are located in the KeyVault under \"vm- -jumpbox-admin-credentials\" Download Git for Windows from https://git-scm.com/download/win and install Download Azure CLI from https://aka.ms/installazurecliwindows and install Open Git Bash Login to Azure az login and set the default subscription if needed: az account set --subscription <subscription_id> Git clone the TRE repository: git clone https://github.com/microsoft/AzureTRE.git Download jq curl -L -o /usr/bin/jq.exe https://github.com/stedolan/jq/releases/latest/download/jq-win64.exe Configure Nexus repository Run the Nexus configuration script to reset the password and setup a PyPI proxy on Nexus: ./scripts/configure_nexus.sh -t <tre_id> Configure Gitea repository Migrate the required repositories to Gitea by running: ./scripts/gitea_migrate_repo.sh -t <tre_id> -g <URL_of_github_repo_to_migrate> If you have issues with token or token doesn't work, you can reset the token by setting it's value to null in Key Vault: az keyvault secret set --name gitea-<tre-id>-admin-token --vault-name kv-<tre-id> --value null","title":"4. Configuring Shared Services"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#configuring-shared-services","text":"Complete the configuration of the shared services (Nexus and Gitea) from inside of the TRE environment.","title":"Configuring Shared Services"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#prepare-the-admin-jumpbox","text":"Sign in to the admin jumpbox provisioned as part of the TRE deployment using Bastion. The credentials for the jumpbox are located in the KeyVault under \"vm- -jumpbox-admin-credentials\" Download Git for Windows from https://git-scm.com/download/win and install Download Azure CLI from https://aka.ms/installazurecliwindows and install Open Git Bash Login to Azure az login and set the default subscription if needed: az account set --subscription <subscription_id> Git clone the TRE repository: git clone https://github.com/microsoft/AzureTRE.git Download jq curl -L -o /usr/bin/jq.exe https://github.com/stedolan/jq/releases/latest/download/jq-win64.exe","title":"Prepare the admin jumpbox"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#configure-nexus-repository","text":"Run the Nexus configuration script to reset the password and setup a PyPI proxy on Nexus: ./scripts/configure_nexus.sh -t <tre_id>","title":"Configure Nexus repository"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#configure-gitea-repository","text":"Migrate the required repositories to Gitea by running: ./scripts/gitea_migrate_repo.sh -t <tre_id> -g <URL_of_github_repo_to_migrate> If you have issues with token or token doesn't work, you can reset the token by setting it's value to null in Key Vault: az keyvault secret set --name gitea-<tre-id>-admin-token --vault-name kv-<tre-id> --value null","title":"Configure Gitea repository"},{"location":"tre-admins/setup-instructions/deploying-azure-tre/","text":"Deploying Azure TRE You are now ready to deploy the Azure TRE instance. Execute the all action of the makefile using make : make all Deploying a new Azure TRE instance takes approximately 30 minutes. Once the deployment is completed, you will be presented with a few output variables similar to the ones below: app_gateway_name = \"agw-mytre\" azure_tre_fqdn = \"mytre.westeurope.cloudapp.azure.com\" core_resource_group_name = \"rg-mytre\" keyvault_name = \"kv-mytre\" log_analytics_name = \"log-mytre\" static_web_storage = \"stwebmytre\" The Azure TRE instance is initially deployed with an invalid self-signed SSL certificate. This certificate needs to be replaced with one valid for your configured domain name. To use a certificate from Let's Encrypt , run the command: make letsencrypt Caution There are rate limits with Let's Encrypt, so this should not be run when not needed. Info If you're using Codespaces, you'll encounter a bug when trying to run make letsencrypt where the incorrect IP will be whitelisted on the storage account and Codespaces won't be able to upload the test file due to a 403 error. The workaround until this is fixed is to temporarily disable the firewall on your stweb{TRE_ID} storage account before running the script, then re-enable afterwards. Validate the deployment Using curl Use curl to make a simple request to the status endpoint of the API: curl https://<azure_tre_fqdn>/api/status The expected response is: { \"services\" :[{ \"service\" : \"Cosmos DB\" , \"status\" : \"OK\" , \"message\" : \"\" }]} You can also create a request to the api/health endpoint to verify that the API is deployed and responds. You should see a pong response as a result of the request below: curl https://<azure_tre_fqdn>/api/health Using the API docs Open your browser and navigate to the /api/docs route of the API: https://<azure_tre_fqdn>/api/docs and click Try it out on the operation of choice. Next steps Install base workspace bundle Deploy a new workspace for Azure Machine Learning Enable users to access the Azure TRE instance Create a new workspace template Tear-down Azure TRE","title":"3. Deploying Azure TRE"},{"location":"tre-admins/setup-instructions/deploying-azure-tre/#deploying-azure-tre","text":"You are now ready to deploy the Azure TRE instance. Execute the all action of the makefile using make : make all Deploying a new Azure TRE instance takes approximately 30 minutes. Once the deployment is completed, you will be presented with a few output variables similar to the ones below: app_gateway_name = \"agw-mytre\" azure_tre_fqdn = \"mytre.westeurope.cloudapp.azure.com\" core_resource_group_name = \"rg-mytre\" keyvault_name = \"kv-mytre\" log_analytics_name = \"log-mytre\" static_web_storage = \"stwebmytre\" The Azure TRE instance is initially deployed with an invalid self-signed SSL certificate. This certificate needs to be replaced with one valid for your configured domain name. To use a certificate from Let's Encrypt , run the command: make letsencrypt Caution There are rate limits with Let's Encrypt, so this should not be run when not needed. Info If you're using Codespaces, you'll encounter a bug when trying to run make letsencrypt where the incorrect IP will be whitelisted on the storage account and Codespaces won't be able to upload the test file due to a 403 error. The workaround until this is fixed is to temporarily disable the firewall on your stweb{TRE_ID} storage account before running the script, then re-enable afterwards.","title":"Deploying Azure TRE"},{"location":"tre-admins/setup-instructions/deploying-azure-tre/#validate-the-deployment","text":"","title":"Validate the deployment"},{"location":"tre-admins/setup-instructions/deploying-azure-tre/#using-curl","text":"Use curl to make a simple request to the status endpoint of the API: curl https://<azure_tre_fqdn>/api/status The expected response is: { \"services\" :[{ \"service\" : \"Cosmos DB\" , \"status\" : \"OK\" , \"message\" : \"\" }]} You can also create a request to the api/health endpoint to verify that the API is deployed and responds. You should see a pong response as a result of the request below: curl https://<azure_tre_fqdn>/api/health","title":"Using curl"},{"location":"tre-admins/setup-instructions/deploying-azure-tre/#using-the-api-docs","text":"Open your browser and navigate to the /api/docs route of the API: https://<azure_tre_fqdn>/api/docs and click Try it out on the operation of choice.","title":"Using the API docs"},{"location":"tre-admins/setup-instructions/deploying-azure-tre/#next-steps","text":"Install base workspace bundle Deploy a new workspace for Azure Machine Learning Enable users to access the Azure TRE instance Create a new workspace template Tear-down Azure TRE","title":"Next steps"},{"location":"tre-admins/setup-instructions/getting-started/","text":"Getting started Prerequisites To deploy an Azure TRE instance, the following assets and tools are required: Azure subscription Azure Active Directory (AAD) tenant in which you can create application registrations Git client such as Git or GitHub Desktop Docker Desktop Development container The Azure TRE solution contains a development container with all the required tooling to develop and deploy the Azure TRE. To deploy an Azure TRE instance using the provided development container you will also need: Visual Studio Code Remote containers extension for Visual Studio Code The files for the dev container are located in /.devcontainer/ folder. Tip An alternative of running the development container locally is to use GitHub Codespaces . Clone the Azure TRE Git repository Clone the Azure TRE Git repository on GitHub to your local computer. git clone https://github.com/microsoft/AzureTRE.git The Git repository will host some basic configuration for the TRE instances that are deployed from a given repository. Create a new branch for the instance that you are about to deploy. cd AzureTRE AzureTRE> git checkout -b quickstartenv Open the cloned repository in Visual Studio Code and connect to the development container. AzureTRE> code . Tip Visual Studio Code should recognize the available development container and ask you to open the folder using it. For additional details on connecting to remote containers, please see the Open an existing folder in a container quickstart. When you start the development container for the first time, the container will be built. This usually takes a few minutes. Next steps Pre-deployment steps","title":"1. Getting Started"},{"location":"tre-admins/setup-instructions/getting-started/#getting-started","text":"","title":"Getting started"},{"location":"tre-admins/setup-instructions/getting-started/#prerequisites","text":"To deploy an Azure TRE instance, the following assets and tools are required: Azure subscription Azure Active Directory (AAD) tenant in which you can create application registrations Git client such as Git or GitHub Desktop Docker Desktop","title":"Prerequisites"},{"location":"tre-admins/setup-instructions/getting-started/#development-container","text":"The Azure TRE solution contains a development container with all the required tooling to develop and deploy the Azure TRE. To deploy an Azure TRE instance using the provided development container you will also need: Visual Studio Code Remote containers extension for Visual Studio Code The files for the dev container are located in /.devcontainer/ folder. Tip An alternative of running the development container locally is to use GitHub Codespaces .","title":"Development container"},{"location":"tre-admins/setup-instructions/getting-started/#clone-the-azure-tre-git-repository","text":"Clone the Azure TRE Git repository on GitHub to your local computer. git clone https://github.com/microsoft/AzureTRE.git The Git repository will host some basic configuration for the TRE instances that are deployed from a given repository. Create a new branch for the instance that you are about to deploy. cd AzureTRE AzureTRE> git checkout -b quickstartenv Open the cloned repository in Visual Studio Code and connect to the development container. AzureTRE> code . Tip Visual Studio Code should recognize the available development container and ask you to open the folder using it. For additional details on connecting to remote containers, please see the Open an existing folder in a container quickstart. When you start the development container for the first time, the container will be built. This usually takes a few minutes.","title":"Clone the Azure TRE Git repository"},{"location":"tre-admins/setup-instructions/getting-started/#next-steps","text":"Pre-deployment steps","title":"Next steps"},{"location":"tre-admins/setup-instructions/installing-base-workspace/","text":"Installing base workspace Publishing and registering the base workspace bundle Run: make bundle-publish DIR=./templates/workspaces/base BUNDLE_TYPE=workspace make bundle-register DIR=./templates/workspaces/base BUNDLE_TYPE=workspace Copy the resulting JSON payload. !!! info If you're using Codespaces, you may encounter a Permission denied issue with the Docker daemon. To fix this, run sudo bash ./devops/scripts/set_docker_sock_permission.sh from the root of the repository, then retry the make command. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/docs Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. Once logged in, click Try it out on the POST /api/workspace-templates operation: Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. To verify registration of the template do GET operation on /api/workspace-templates . The name of the template should now be listed. Creating a base workspace Now that we have published and registered a base workspace bundle we can use the deployed API to create a base workspace. Info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. As explained in the auth guide , every workspace has a corresponding app registration which can be created using the helper script scripts/aad-app-reg.sh . For example: ./scripts/aad-app-reg.sh --name 'Workspace One' --swaggerui-redirecturl https://mytre.region.cloudapp.azure.com/api/docs/oauth2-redirect --workspace Caution If you're using a separate tenant for AAD app registrations to the one where you've deployed the TRE infrastructure resources, ensure you've signed into that tenant in the az cli before running the above command. See Using a separate Azure Active Directory tenant in Pre-deployment steps for more details. Running the script will report WORKSPACE_API_CLIENT_ID for the generated app which needs to be used in the POST body below. Go to https://<azure_tre_fqdn>/api/docs and use POST /api/workspaces with the sample body to create a base workspace. { \"templateName\" : \"tre-workspace-base\" , \"properties\" : { \"display_name\" : \"manual-from-swagger\" , \"description\" : \"workspace for team X\" , \"app_id\" : \"WORKSPACE_API_CLIENT_ID\" , \"address_space_size\" : \"medium\" } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Workspace level operations can now be carried out using the workspace API, at /api/workspaces/<workspace_id>/docs/ . Next steps Installing a workspace service","title":"5. Installing Base Workspace"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#installing-base-workspace","text":"","title":"Installing base workspace"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#publishing-and-registering-the-base-workspace-bundle","text":"Run: make bundle-publish DIR=./templates/workspaces/base BUNDLE_TYPE=workspace make bundle-register DIR=./templates/workspaces/base BUNDLE_TYPE=workspace Copy the resulting JSON payload. !!! info If you're using Codespaces, you may encounter a Permission denied issue with the Docker daemon. To fix this, run sudo bash ./devops/scripts/set_docker_sock_permission.sh from the root of the repository, then retry the make command. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/docs Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. Once logged in, click Try it out on the POST /api/workspace-templates operation: Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. To verify registration of the template do GET operation on /api/workspace-templates . The name of the template should now be listed.","title":"Publishing and registering the base workspace bundle"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#creating-a-base-workspace","text":"Now that we have published and registered a base workspace bundle we can use the deployed API to create a base workspace. Info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. As explained in the auth guide , every workspace has a corresponding app registration which can be created using the helper script scripts/aad-app-reg.sh . For example: ./scripts/aad-app-reg.sh --name 'Workspace One' --swaggerui-redirecturl https://mytre.region.cloudapp.azure.com/api/docs/oauth2-redirect --workspace Caution If you're using a separate tenant for AAD app registrations to the one where you've deployed the TRE infrastructure resources, ensure you've signed into that tenant in the az cli before running the above command. See Using a separate Azure Active Directory tenant in Pre-deployment steps for more details. Running the script will report WORKSPACE_API_CLIENT_ID for the generated app which needs to be used in the POST body below. Go to https://<azure_tre_fqdn>/api/docs and use POST /api/workspaces with the sample body to create a base workspace. { \"templateName\" : \"tre-workspace-base\" , \"properties\" : { \"display_name\" : \"manual-from-swagger\" , \"description\" : \"workspace for team X\" , \"app_id\" : \"WORKSPACE_API_CLIENT_ID\" , \"address_space_size\" : \"medium\" } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Workspace level operations can now be carried out using the workspace API, at /api/workspaces/<workspace_id>/docs/ .","title":"Creating a base workspace"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#next-steps","text":"Installing a workspace service","title":"Next steps"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/","text":"Installing workspace service and user resource Publish and register a workspace service template We will use the Guacamole workspace service bundle for the purposes of this tutorial. These steps can be repeated for any workspace service template. Run: make bundle-publish DIR=./templates/workspace_services/guacamole BUNDLE_TYPE=workspace_service make bundle-register DIR=./templates/workspace_services/guacamole BUNDLE_TYPE=workspace_service Copy the resulting JSON payload. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/docs . Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. Once logged in, click Try it out on the POST /api/workspace-service-templates operation. Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. To verify registration of the template do GET operation on /api/workspace-service-templates . The name of the template should now be listed. Publish and register a user resource template The Guacamole workspace service also has user resources, there are the VMs that researchers will deploy. These steps can be repeated for any user resource template. Run: make bundle-publish DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm BUNDLE_TYPE=user_resource make bundle-register DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm BUNDLE_TYPE=user_resource Copy the resulting JSON payload. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/docs . Log into the Swagger UI by clicking Authorize, then Authorize again. You will be redirected to the login page. Once logged in, click Try it out on the POST /api/workspace-service-templates/<service_template_name>/user-resource-templates operation. In the service_template_name field, paste the name of the workspace service template that you registered earlier - tre-service-guacamole . Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. To verify registration of the template do GET operation on /api/workspace-service-templates/<service_template_name>/user-resource-templates . The name of the template should now be listed. Creating a workspace service Now that we have published and registered both workspace service and user resource bundles we can use the workspace API to create a workspace service in our workspace. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of the workspace created in the previous step. !!! info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. !!! info You need to log in with a user with assigned the WorkspaceOwner role in the app regsitration used when deploying your workspace. Once logged in, click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services operation. Enter the workspace_id in the workspace_id field. Paste the following payload json into the Request body field, update <WORKSPACE_API_CLIENT_ID> with the client ID of the app registration for the base workspace you created previously, then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole\" , \"properties\" : { \"display_name\" : \"Virtual Desktop\" , \"description\" : \"Create virtual desktops for running research workloads\" , \"openid_client_id\" : \"<WORKSPACE_API_CLIENT_ID>\" , \"is_exposed_externally\" : true , \"guac_disable_copy\" : true , \"guac_disable_paste\" : true } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. Record this ID for later use. You can also follow the progress in Azure portal as various resources come up. Info There is currently a bug where the redirect URI isn't automatically set up correctly in the Workspace API app registration. Until this is fixed, you need to head to the app registration in the Azure portal, click on Add a redirect URI > Add a platform > Web > then paste in the Guacamole URI in the redirect URI box. You can find this in the Guacamole app service properties and append /guacamole/ to the end - it should look like this: https://guacamole-{TRE_ID}-ws-XXXX-svc-XXXX.azurewebsites.net/guacamole/ ). Finally, make sure you check the ID tokens checkbox and click Configure . Creating a user resource Once the workspace service has been created, we can use the workspace API to create a user resource in our workspace. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of your workspace. Click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services/<service_id>/user_resources operation. Where <workspace_id> and <service_id> are the workspace ID of your workspace and workspace service ID of your workspace service. Enter the workspace ID and workspace service id in the workspace_id and service_id fields. Paste the following payload json into the Request body field, then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole-windowsvm\" , \"properties\" : { \"display_name\" : \"My VM\" , \"description\" : \"Will be using this VM for my research\" , \"os_image\" : \"Server 2019 Data Science VM\" } } Note: You can also specify \"Windows 10\" for a standard Windows 10 image The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Once deployment has completed you can connect to the user resource using the connection_uri property returned by the API.","title":"6. Installing Workspace Service and User Resource"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#installing-workspace-service-and-user-resource","text":"","title":"Installing workspace service and user resource"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#publish-and-register-a-workspace-service-template","text":"We will use the Guacamole workspace service bundle for the purposes of this tutorial. These steps can be repeated for any workspace service template. Run: make bundle-publish DIR=./templates/workspace_services/guacamole BUNDLE_TYPE=workspace_service make bundle-register DIR=./templates/workspace_services/guacamole BUNDLE_TYPE=workspace_service Copy the resulting JSON payload. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/docs . Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. Once logged in, click Try it out on the POST /api/workspace-service-templates operation. Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. To verify registration of the template do GET operation on /api/workspace-service-templates . The name of the template should now be listed.","title":"Publish and register a workspace service template"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#publish-and-register-a-user-resource-template","text":"The Guacamole workspace service also has user resources, there are the VMs that researchers will deploy. These steps can be repeated for any user resource template. Run: make bundle-publish DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm BUNDLE_TYPE=user_resource make bundle-register DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm BUNDLE_TYPE=user_resource Copy the resulting JSON payload. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/docs . Log into the Swagger UI by clicking Authorize, then Authorize again. You will be redirected to the login page. Once logged in, click Try it out on the POST /api/workspace-service-templates/<service_template_name>/user-resource-templates operation. In the service_template_name field, paste the name of the workspace service template that you registered earlier - tre-service-guacamole . Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. To verify registration of the template do GET operation on /api/workspace-service-templates/<service_template_name>/user-resource-templates . The name of the template should now be listed.","title":"Publish and register a user resource template"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#creating-a-workspace-service","text":"Now that we have published and registered both workspace service and user resource bundles we can use the workspace API to create a workspace service in our workspace. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of the workspace created in the previous step. !!! info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. !!! info You need to log in with a user with assigned the WorkspaceOwner role in the app regsitration used when deploying your workspace. Once logged in, click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services operation. Enter the workspace_id in the workspace_id field. Paste the following payload json into the Request body field, update <WORKSPACE_API_CLIENT_ID> with the client ID of the app registration for the base workspace you created previously, then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole\" , \"properties\" : { \"display_name\" : \"Virtual Desktop\" , \"description\" : \"Create virtual desktops for running research workloads\" , \"openid_client_id\" : \"<WORKSPACE_API_CLIENT_ID>\" , \"is_exposed_externally\" : true , \"guac_disable_copy\" : true , \"guac_disable_paste\" : true } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. Record this ID for later use. You can also follow the progress in Azure portal as various resources come up. Info There is currently a bug where the redirect URI isn't automatically set up correctly in the Workspace API app registration. Until this is fixed, you need to head to the app registration in the Azure portal, click on Add a redirect URI > Add a platform > Web > then paste in the Guacamole URI in the redirect URI box. You can find this in the Guacamole app service properties and append /guacamole/ to the end - it should look like this: https://guacamole-{TRE_ID}-ws-XXXX-svc-XXXX.azurewebsites.net/guacamole/ ). Finally, make sure you check the ID tokens checkbox and click Configure .","title":"Creating a workspace service"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#creating-a-user-resource","text":"Once the workspace service has been created, we can use the workspace API to create a user resource in our workspace. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of your workspace. Click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services/<service_id>/user_resources operation. Where <workspace_id> and <service_id> are the workspace ID of your workspace and workspace service ID of your workspace service. Enter the workspace ID and workspace service id in the workspace_id and service_id fields. Paste the following payload json into the Request body field, then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole-windowsvm\" , \"properties\" : { \"display_name\" : \"My VM\" , \"description\" : \"Will be using this VM for my research\" , \"os_image\" : \"Server 2019 Data Science VM\" } } Note: You can also specify \"Windows 10\" for a standard Windows 10 image The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Once deployment has completed you can connect to the user resource using the connection_uri property returned by the API.","title":"Creating a user resource"},{"location":"tre-admins/setup-instructions/pre-deployment-steps/","text":"Pre-deployment steps Info See Environment variables for full details of the deployment related variables. Set environment configuration variables of shared management resources Open the /devops/.env.sample file and then save it without the .sample extension. You should now have a file called .env located in the /devops folder. The file contains configuration variables for the shared management infrastructure which is used to support the deployment of one or more Azure TRE instances. Provide the values for the following variables: Variable Description LOCATION The Azure location (region) for all resources. E.g., westeurope MGMT_RESOURCE_GROUP_NAME The shared resource group for all management resources, including the storage account. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. ARM_SUBSCRIPTION_ID The Azure subscription ID for all resources. Tip To retrieve your Azure subscription ID, use the az command line interface available in the development container. In the terminal window in Visual Studio Code, type az login followed by az account show to see your default subscription. Please refer to az account -help for further details on how to change your active subscription. The rest of the variables can have their default values. You should now have a .env file that looks similar to the one below: # Management infrastructure LOCATION=westeurope MGMT_RESOURCE_GROUP_NAME=aztremgmt MGMT_STORAGE_ACCOUNT_NAME=aztremgmt TERRAFORM_STATE_CONTAINER_NAME=tfstate ACR_NAME=aztreacr ARM_SUBSCRIPTION_ID=12...54e # If you want to override the currently signed in credentials # ARM_TENANT_ID=__CHANGE_ME__ # ARM_CLIENT_ID=__CHANGE_ME__ # ARM_CLIENT_SECRET=__CHANGE_ME__ # Debug mode DEBUG=\"false\" Set environment configuration variables of the Azure TRE instance Next, you will set the configuration variables for the specific Azure TRE instance: Use the terminal window in Visual Studio Code to execute the following script from within the development container: az login Note In case you have several subscriptions and would like to change your default subscription use az account set --subscription <desired subscription ID> Open the /templates/core/.env.sample file and then save it without the .sample extension. You should now have a file called .env located in the /templates/core folder. Set the first one of the variables, TRE_ID , which is the alphanumeric, with underscores and hyphens allowed, ID for the Azure TRE instance. The value will be used in various Azure resources, and needs to be globally unique and less than 12 characters in length . Use only lowercase letters. Choose wisely! Run the /scripts/aad-app-reg.sh script to create API and Swagger UI app registrations and their service principals in Azure Active Directory. The details of the script are covered app registration script section of the auth document. Below is a sample where TRE_ID has value mytre and the Azure location is westeurope : ./scripts/aad-app-reg.sh --name TRE --swaggerui-redirecturl https://mytre.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect --admin-consent Note The full functionality of the script requires directory admin privileges. You may need to contact your friendly Azure Active Directory admin to complete this step. The app registrations can be created manually in Azure Portal too. For more information, see Authentication and authorization . Note If you don't have permissions and just want to create a development environment then skip this step and see the steps in the \"Using a separate Azure Active Directory tenant) below. With the output of the script, you can now provide the required auth related values for the following variables in the /templates/core/.env configuration file: Variable Description AAD_TENANT_ID The Azure AD Tenant ID. API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. All other variables can have their default values for now. You should now have a .env file that looks similar to below: # Used for TRE deployment TRE_ID=mytre CORE_ADDRESS_SPACE=\"10.1.0.0/22\" TRE_ADDRESS_SPACE=\"10.0.0.0/12\" DEPLOY_GITEA=true RESOURCE_PROCESSOR_TYPE=\"vmss_porter\" # Auth configuration AAD_TENANT_ID=72e...45 API_CLIENT_ID=af6...dc API_CLIENT_SECRET=abc...12 SWAGGER_UI_CLIENT_ID=d87...12 Using a separate Azure Active Directory tenant Caution This section is only relevant it you are setting up a separate Azure Active Directory tenant for use. This is only recommended for development environments when you don't have the required permissions to create the necessary Azure Active Directory registrations. Using a separate Azure Active Directory tenant will prevent you from using certain Azure Active Directory integrated services. For production deployments, work with your Azure Active Directory administrator to perform the required registration Create an Azure Active Directory tenant To create a new Azure Active Directory tenant, follow the steps here Sign in to the new tenant Sign in to the new tenant by running the following command (substitute the ID of the tenant you just created) az login --tenant <tenant-id-here> --allow-no-subscriptions Run the /scripts/aad-app-reg.sh script to create API and Swagger UI app registrations and their service principals in Azure Active Directory. The details of the script are covered app registration script section of the auth document. Below is a sample where TRE_ID has value mytre and the Azure location is westeurope : ./scripts/aad-app-reg.sh --name TRE --swaggerui-redirecturl https://mytre.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect --admin-consent With the output of the script, you can now provide the required auth related values for the following variables in the /templates/core/.env configuration file as described above in the \"Set environment configuration variables of the Azure TRE instance\" section. Reset your az account to use the subscription you want to deploy resources into ( az list will show the subscriptions you are signed into) az account set --subscription <name or id of subscription> Add admin user Make sure the TRE Administrators and TRE Users roles, defined by the API app registration, are assigned to your user and others as required. See Enabling users for instructions. Next steps Deploying Azure TRE","title":"2. Pre-deployment Steps"},{"location":"tre-admins/setup-instructions/pre-deployment-steps/#pre-deployment-steps","text":"Info See Environment variables for full details of the deployment related variables.","title":"Pre-deployment steps"},{"location":"tre-admins/setup-instructions/pre-deployment-steps/#set-environment-configuration-variables-of-shared-management-resources","text":"Open the /devops/.env.sample file and then save it without the .sample extension. You should now have a file called .env located in the /devops folder. The file contains configuration variables for the shared management infrastructure which is used to support the deployment of one or more Azure TRE instances. Provide the values for the following variables: Variable Description LOCATION The Azure location (region) for all resources. E.g., westeurope MGMT_RESOURCE_GROUP_NAME The shared resource group for all management resources, including the storage account. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. ARM_SUBSCRIPTION_ID The Azure subscription ID for all resources. Tip To retrieve your Azure subscription ID, use the az command line interface available in the development container. In the terminal window in Visual Studio Code, type az login followed by az account show to see your default subscription. Please refer to az account -help for further details on how to change your active subscription. The rest of the variables can have their default values. You should now have a .env file that looks similar to the one below: # Management infrastructure LOCATION=westeurope MGMT_RESOURCE_GROUP_NAME=aztremgmt MGMT_STORAGE_ACCOUNT_NAME=aztremgmt TERRAFORM_STATE_CONTAINER_NAME=tfstate ACR_NAME=aztreacr ARM_SUBSCRIPTION_ID=12...54e # If you want to override the currently signed in credentials # ARM_TENANT_ID=__CHANGE_ME__ # ARM_CLIENT_ID=__CHANGE_ME__ # ARM_CLIENT_SECRET=__CHANGE_ME__ # Debug mode DEBUG=\"false\"","title":"Set environment configuration variables of shared management resources"},{"location":"tre-admins/setup-instructions/pre-deployment-steps/#set-environment-configuration-variables-of-the-azure-tre-instance","text":"Next, you will set the configuration variables for the specific Azure TRE instance: Use the terminal window in Visual Studio Code to execute the following script from within the development container: az login Note In case you have several subscriptions and would like to change your default subscription use az account set --subscription <desired subscription ID> Open the /templates/core/.env.sample file and then save it without the .sample extension. You should now have a file called .env located in the /templates/core folder. Set the first one of the variables, TRE_ID , which is the alphanumeric, with underscores and hyphens allowed, ID for the Azure TRE instance. The value will be used in various Azure resources, and needs to be globally unique and less than 12 characters in length . Use only lowercase letters. Choose wisely! Run the /scripts/aad-app-reg.sh script to create API and Swagger UI app registrations and their service principals in Azure Active Directory. The details of the script are covered app registration script section of the auth document. Below is a sample where TRE_ID has value mytre and the Azure location is westeurope : ./scripts/aad-app-reg.sh --name TRE --swaggerui-redirecturl https://mytre.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect --admin-consent Note The full functionality of the script requires directory admin privileges. You may need to contact your friendly Azure Active Directory admin to complete this step. The app registrations can be created manually in Azure Portal too. For more information, see Authentication and authorization . Note If you don't have permissions and just want to create a development environment then skip this step and see the steps in the \"Using a separate Azure Active Directory tenant) below. With the output of the script, you can now provide the required auth related values for the following variables in the /templates/core/.env configuration file: Variable Description AAD_TENANT_ID The Azure AD Tenant ID. API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. All other variables can have their default values for now. You should now have a .env file that looks similar to below: # Used for TRE deployment TRE_ID=mytre CORE_ADDRESS_SPACE=\"10.1.0.0/22\" TRE_ADDRESS_SPACE=\"10.0.0.0/12\" DEPLOY_GITEA=true RESOURCE_PROCESSOR_TYPE=\"vmss_porter\" # Auth configuration AAD_TENANT_ID=72e...45 API_CLIENT_ID=af6...dc API_CLIENT_SECRET=abc...12 SWAGGER_UI_CLIENT_ID=d87...12","title":"Set environment configuration variables of the Azure TRE instance"},{"location":"tre-admins/setup-instructions/pre-deployment-steps/#using-a-separate-azure-active-directory-tenant","text":"Caution This section is only relevant it you are setting up a separate Azure Active Directory tenant for use. This is only recommended for development environments when you don't have the required permissions to create the necessary Azure Active Directory registrations. Using a separate Azure Active Directory tenant will prevent you from using certain Azure Active Directory integrated services. For production deployments, work with your Azure Active Directory administrator to perform the required registration Create an Azure Active Directory tenant To create a new Azure Active Directory tenant, follow the steps here Sign in to the new tenant Sign in to the new tenant by running the following command (substitute the ID of the tenant you just created) az login --tenant <tenant-id-here> --allow-no-subscriptions Run the /scripts/aad-app-reg.sh script to create API and Swagger UI app registrations and their service principals in Azure Active Directory. The details of the script are covered app registration script section of the auth document. Below is a sample where TRE_ID has value mytre and the Azure location is westeurope : ./scripts/aad-app-reg.sh --name TRE --swaggerui-redirecturl https://mytre.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect --admin-consent With the output of the script, you can now provide the required auth related values for the following variables in the /templates/core/.env configuration file as described above in the \"Set environment configuration variables of the Azure TRE instance\" section. Reset your az account to use the subscription you want to deploy resources into ( az list will show the subscriptions you are signed into) az account set --subscription <name or id of subscription>","title":"Using a separate Azure Active Directory tenant"},{"location":"tre-admins/setup-instructions/pre-deployment-steps/#add-admin-user","text":"Make sure the TRE Administrators and TRE Users roles, defined by the API app registration, are assigned to your user and others as required. See Enabling users for instructions.","title":"Add admin user"},{"location":"tre-admins/setup-instructions/pre-deployment-steps/#next-steps","text":"Deploying Azure TRE","title":"Next steps"},{"location":"tre-admins/setup-instructions/tear-down/","text":"Tear-down To remove the Azure TRE and its resources from your Azure subscription run: make tre-destroy Alternatively, you can delete the resource groups in Azure Portal or using the CLI: az group delete --name <resource group name> Finally, delete the app registrations in Azure Portal or using the CLI: az ad app delete --id <application client ID>","title":"Tear-down"},{"location":"tre-admins/setup-instructions/tear-down/#tear-down","text":"To remove the Azure TRE and its resources from your Azure subscription run: make tre-destroy Alternatively, you can delete the resource groups in Azure Portal or using the CLI: az group delete --name <resource group name> Finally, delete the app registrations in Azure Portal or using the CLI: az ad app delete --id <application client ID>","title":"Tear-down"},{"location":"tre-admins/setup-instructions/workflows/","text":"GitHub Actions workflows (CI/CD) To deploy the Azure TRE using GitHub workflows, create a fork of the repository. Deployment is done using the /.github/workflows/deploy_tre.yml workflow. This method is also used to deploy the dev/test environment for the original Azure TRE repository. Setup instructions Before you can run the deploy_tre.yml pipeline there are some one-time configuration steps that we need to do, similar to the Pre-deployment steps for manual deployment. Tip In some of the steps below, you are asked to configure repository secrets. Follow the GitHub guide on creating repository secrets if you are unfamiliar with this step. Create a service principal for the subscription so that the workflow can provision Azure resources. Decide on a TRE ID and the location for the Azure resources Create app registrations for API authentication Create app registrations and a user for the E2E tests Create a workspace app registration for setting up workspaces (for the E2E tests) Create a Teams WebHook for deployment notifications Configure repository secrets Deploy the TRE using the workflow Create a service principal for provisioning resources Login to Azure Log in to Azure using az login and select the Azure subscription you wish to deploy Azure TRE to: az login az account list az account set --subscription <subscription ID> Caution When running locally the credentials of the logged-in user will be used to deploy the infrastructure. Hence, it is essential that the user has enough permissions to deploy all resources. See Sign in with Azure CLI for more details. Create a service principal A service principal needs to be created to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. Create a main service principal with \" Owner \" role: az ad sp create-for-rbac --name \"sp-aztre-core\" --role Owner --scopes /subscriptions/<subscription_id> --sdk-auth Caution Save the JSON output locally - as you will need it later for setting secrets in the build Configure the repository secrets. These values will be in the JSON file from the previous step. Secret name Description ARM_SUBSCRIPTION_ID The Azure subscription to deploy to ARM_TENANT_ID The Azure tenant to deploy to ARM_CLIENT_ID The Azure Client Id (user) ARM_CLIENT_SECRET The Azure Client Secret (password) Decide on a TRE ID and Azure resources location Configure the TRE ID and LOCATION repository secrets Secret name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of tre-dev-42 will result in a resource group name for Azure TRE instance of rg-tre-dev-42 . This must be less than 12 characters. Allowed characters: Alphanumeric, underscores, and hyphens. LOCATION The Azure location (region) for all resources. E.g. westeurope Create app registrations for API authentication Follow the instructions to run the app registration script in the Authentication and Authorization document . Use the values for TRE ID and LOCATION from above. Configure the TRE API and Swagger UI repository secrets Secret name Description AAD_TENANT_ID The tenant ID of the Azure AD. SWAGGER_UI_CLIENT_ID The application (client) ID of the TRE Swagger UI app. API_CLIENT_ID The application (client) ID of the TRE API app. API_CLIENT_SECRET The application password (client secret) of the TRE API app. Create an app registration and a user for the E2E tests Follow the instructions to create an app registration and a test user for the E2E tests in the Authentication and Authorization document. Configure the E2E Test repository secrets Secret name Description TEST_APP_ID The application (client) ID of the E2E Test app TEST_USER_NAME The username of the E2E Test User TEST_USER_PASSWORD The password of the E2E Test User Create a workspace app registration for setting up workspaces (for the E2E tests) Follow the instructions to create a workspace app registration (used for the E2E tests) - and make the E2E test user a WorkspaceOwner for the app registration. Configure the TEST_WORKSPACE_APP_ID repository secret Secret name Description TEST_WORKSPACE_APP_ID The application (client) ID of the Workspaces app. Create a Teams Webhook for deployment notifications The deploy_tre.yml workflow sends a notification to a Microsoft Teams channel when it finishes running. Note If you don't want to notify a channel, you can also remove the Notify dedicated teams channel steps in the pipeline Follow the Microsoft Docs to create a webhook for your channel Configure the MS_TEAMS_WEBHOOK_URI repository secret Secret name Description MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook Configure repository secrets Configure additional repository secrets used in the deployment pipeline Secret name Description MGMT_RESOURCE_GROUP The name of the shared resource group for all Azure TRE core resources. STATE_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. E.g. mystorageaccount . TF_STATE_CONTAINER The name of the blob container to hold the Terraform state. By convention the value is tfstate . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. E.g. 10.1.0.0/22 . Recommended /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 DEPLOY_GITEA If set to false disables deployment of the Gitea shared service. DEPLOY_NEXUS If set to false disables deployment of the Nexus shared service. Deploy the TRE using the workflow With all the repository secrets set, you can trigger a workflow run by pushing to develop/main of your fork, or by dispatching the workflow manually. Pull request security Many of the workflows access GitHub repository secrets and malicious code in workflows pose a security risk. Thus, pull requests (PRs) from forks cannot be allowed to execute workflows freely. By default, workflows are not run by pull requests from forks, but can be enabled with pull_request_target event . However, changes reviewed and found safe should be able to execute workflows. A label, that can only be assigned by authorized project members, can be used to safeguard workflow execution: on : pull_request_target : types : [ labeled ] branches : [ main ] jobs : my_job : if : | github.event.pull_request.head.repo.full_name == github.repository || contains(github.event.pull_request.labels.*.name, 'safe to test') The snippet above contains two conditions: Checking the name of the originating repository of the PR. In case the PR is from a fork the condition evaluates to false . github.repository (see github context ) evaluates into string e.g., \"microsoft/AzureTRE\". Checking if the pull request has a label \"safe to test\". Effectively, the two conditions allow the job execution for all PRs originating from internal branches, but only allow PRs originating from a fork with \"safe to test\" label assigned to do so. The workflows of fork PRs will remain in \"skipped\" state until the label is set. Caution Any job without the condition is allowed to execute even if the PR originates from a fork.","title":"3b. Deploying Azure TRE with GitHub workflows"},{"location":"tre-admins/setup-instructions/workflows/#github-actions-workflows-cicd","text":"To deploy the Azure TRE using GitHub workflows, create a fork of the repository. Deployment is done using the /.github/workflows/deploy_tre.yml workflow. This method is also used to deploy the dev/test environment for the original Azure TRE repository.","title":"GitHub Actions workflows (CI/CD)"},{"location":"tre-admins/setup-instructions/workflows/#setup-instructions","text":"Before you can run the deploy_tre.yml pipeline there are some one-time configuration steps that we need to do, similar to the Pre-deployment steps for manual deployment. Tip In some of the steps below, you are asked to configure repository secrets. Follow the GitHub guide on creating repository secrets if you are unfamiliar with this step. Create a service principal for the subscription so that the workflow can provision Azure resources. Decide on a TRE ID and the location for the Azure resources Create app registrations for API authentication Create app registrations and a user for the E2E tests Create a workspace app registration for setting up workspaces (for the E2E tests) Create a Teams WebHook for deployment notifications Configure repository secrets Deploy the TRE using the workflow","title":"Setup instructions"},{"location":"tre-admins/setup-instructions/workflows/#create-a-service-principal-for-provisioning-resources","text":"Login to Azure Log in to Azure using az login and select the Azure subscription you wish to deploy Azure TRE to: az login az account list az account set --subscription <subscription ID> Caution When running locally the credentials of the logged-in user will be used to deploy the infrastructure. Hence, it is essential that the user has enough permissions to deploy all resources. See Sign in with Azure CLI for more details. Create a service principal A service principal needs to be created to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. Create a main service principal with \" Owner \" role: az ad sp create-for-rbac --name \"sp-aztre-core\" --role Owner --scopes /subscriptions/<subscription_id> --sdk-auth Caution Save the JSON output locally - as you will need it later for setting secrets in the build Configure the repository secrets. These values will be in the JSON file from the previous step. Secret name Description ARM_SUBSCRIPTION_ID The Azure subscription to deploy to ARM_TENANT_ID The Azure tenant to deploy to ARM_CLIENT_ID The Azure Client Id (user) ARM_CLIENT_SECRET The Azure Client Secret (password)","title":"Create a service principal for provisioning resources"},{"location":"tre-admins/setup-instructions/workflows/#decide-on-a-tre-id-and-azure-resources-location","text":"Configure the TRE ID and LOCATION repository secrets Secret name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of tre-dev-42 will result in a resource group name for Azure TRE instance of rg-tre-dev-42 . This must be less than 12 characters. Allowed characters: Alphanumeric, underscores, and hyphens. LOCATION The Azure location (region) for all resources. E.g. westeurope","title":"Decide on a TRE ID and Azure resources location"},{"location":"tre-admins/setup-instructions/workflows/#create-app-registrations-for-api-authentication","text":"Follow the instructions to run the app registration script in the Authentication and Authorization document . Use the values for TRE ID and LOCATION from above. Configure the TRE API and Swagger UI repository secrets Secret name Description AAD_TENANT_ID The tenant ID of the Azure AD. SWAGGER_UI_CLIENT_ID The application (client) ID of the TRE Swagger UI app. API_CLIENT_ID The application (client) ID of the TRE API app. API_CLIENT_SECRET The application password (client secret) of the TRE API app.","title":"Create app registrations for API authentication"},{"location":"tre-admins/setup-instructions/workflows/#create-an-app-registration-and-a-user-for-the-e2e-tests","text":"Follow the instructions to create an app registration and a test user for the E2E tests in the Authentication and Authorization document. Configure the E2E Test repository secrets Secret name Description TEST_APP_ID The application (client) ID of the E2E Test app TEST_USER_NAME The username of the E2E Test User TEST_USER_PASSWORD The password of the E2E Test User","title":"Create an app registration and a user for the E2E tests"},{"location":"tre-admins/setup-instructions/workflows/#create-a-workspace-app-registration-for-setting-up-workspaces-for-the-e2e-tests","text":"Follow the instructions to create a workspace app registration (used for the E2E tests) - and make the E2E test user a WorkspaceOwner for the app registration. Configure the TEST_WORKSPACE_APP_ID repository secret Secret name Description TEST_WORKSPACE_APP_ID The application (client) ID of the Workspaces app.","title":"Create a workspace app registration for setting up workspaces (for the E2E tests)"},{"location":"tre-admins/setup-instructions/workflows/#create-a-teams-webhook-for-deployment-notifications","text":"The deploy_tre.yml workflow sends a notification to a Microsoft Teams channel when it finishes running. Note If you don't want to notify a channel, you can also remove the Notify dedicated teams channel steps in the pipeline Follow the Microsoft Docs to create a webhook for your channel Configure the MS_TEAMS_WEBHOOK_URI repository secret Secret name Description MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook","title":"Create a Teams Webhook for deployment notifications"},{"location":"tre-admins/setup-instructions/workflows/#configure-repository-secrets","text":"Configure additional repository secrets used in the deployment pipeline Secret name Description MGMT_RESOURCE_GROUP The name of the shared resource group for all Azure TRE core resources. STATE_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. E.g. mystorageaccount . TF_STATE_CONTAINER The name of the blob container to hold the Terraform state. By convention the value is tfstate . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. E.g. 10.1.0.0/22 . Recommended /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 DEPLOY_GITEA If set to false disables deployment of the Gitea shared service. DEPLOY_NEXUS If set to false disables deployment of the Nexus shared service.","title":"Configure repository secrets"},{"location":"tre-admins/setup-instructions/workflows/#deploy-the-tre-using-the-workflow","text":"With all the repository secrets set, you can trigger a workflow run by pushing to develop/main of your fork, or by dispatching the workflow manually.","title":"Deploy the TRE using the workflow"},{"location":"tre-admins/setup-instructions/workflows/#pull-request-security","text":"Many of the workflows access GitHub repository secrets and malicious code in workflows pose a security risk. Thus, pull requests (PRs) from forks cannot be allowed to execute workflows freely. By default, workflows are not run by pull requests from forks, but can be enabled with pull_request_target event . However, changes reviewed and found safe should be able to execute workflows. A label, that can only be assigned by authorized project members, can be used to safeguard workflow execution: on : pull_request_target : types : [ labeled ] branches : [ main ] jobs : my_job : if : | github.event.pull_request.head.repo.full_name == github.repository || contains(github.event.pull_request.labels.*.name, 'safe to test') The snippet above contains two conditions: Checking the name of the originating repository of the PR. In case the PR is from a fork the condition evaluates to false . github.repository (see github context ) evaluates into string e.g., \"microsoft/AzureTRE\". Checking if the pull request has a label \"safe to test\". Effectively, the two conditions allow the job execution for all PRs originating from internal branches, but only allow PRs originating from a fork with \"safe to test\" label assigned to do so. The workflows of fork PRs will remain in \"skipped\" state until the label is set. Caution Any job without the condition is allowed to execute even if the PR originates from a fork.","title":"Pull request security"},{"location":"tre-developers/api/","text":"TRE API The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace. Prerequisites Tools Python >= 3.8 with pip Azure resources Application Insights - Not required for testing locally Azure Cosmos DB (SQL) You can use the Cosmos DB Emulator for testing locally Azure Service Bus Service principal for the API to access Azure services such as Azure Service Bus AAD applications (for the API and Swagger UI) - see Authentication & authorization for more information Creating resources (Bash) The following snippets can be used to create resources for local testing with Bash shell. Sign in with Azure CLI: az login az account list az account set --subscription <subscription ID> Provision Azure Service Bus: RESOURCE_GROUP = <resource group name> LOCATION = westeurope SERVICE_BUS_NAMESPACE = <service bus namespace name> SERVICE_BUS_RESOURCE_REQUEST_QUEUE = workspacequeue SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE = deploymentstatus az servicebus namespace create --resource-group $RESOURCE_GROUP --name $SERVICE_BUS_NAMESPACE --location $LOCATION az servicebus queue create --resource-group $RESOURCE_GROUP --namespace-name $SERVICE_BUS_NAMESPACE --name $SERVICE_BUS_RESOURCE_REQUEST_QUEUE az servicebus queue create --resource-group $RESOURCE_GROUP --namespace-name $SERVICE_BUS_NAMESPACE --name $SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE Provision Azure Cosmos DB: COSMOS_NAME = <cosmos_name> COSMOS_DB_NAME = <database_name> az cosmosdb create -n $COSMOS_NAME -g $RESOURCE_GROUP --locations regionName = $LOCATION az cosmosdb sql database create -a $COSMOS_NAME -g $RESOURCE_GROUP -n $COSMOS_DB_NAME Create a service principal and assign it permissions to access Service Bus and Cosmos: az ad sp create-for-rbac --name <service principal name> SERVICE_PRINCIPAL_ID = <the AppId of the Service Principal> SUBSCRIPTION_ID = $( az account show --query id --output tsv ) az role assignment create \\ --role \"Azure Service Bus Data Sender\" \\ --assignee $SERVICE_PRINCIPAL_ID \\ --scope /subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RESOURCE_GROUP /providers/Microsoft.ServiceBus/namespaces/ $SERVICE_BUS_NAMESPACE az role assignment create \\ --role \"Azure Service Bus Data Receiver\" \\ --assignee $SERVICE_PRINCIPAL_ID \\ --scope /subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RESOURCE_GROUP /providers/Microsoft.ServiceBus/namespaces/ $SERVICE_BUS_NAMESPACE az role assignment create \\ --role \"Contributor\" \\ --assignee $SERVICE_PRINCIPAL_ID \\ --scope /subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RESOURCE_GROUP /providers/Microsoft.DocumentDB/databaseAccounts/ $COSMOS_NAME Caution Keep in mind that Azure role assignments may take up to five minutes to propagate. Configuration General Environment variable name Description DEBUG When set to True , the debugging information for unhandled exceptions is shown in the Swagger UI and logging is more verbose. TRE_ID The Azure TRE instance name - used for deployment of resources (can be set to anything when debugging locally). Example value: mytre-dev-3142 RESOURCE_LOCATION The location (region) to deploy resources (e.g., workspaces) to. This can be set to anything as the deployment service is not called locally. Example value: westeurope Authentication and Authorization The TRE API depends on TRE API and TRE Swagger UI app registrations. The API requires the environment variables listed in the table below to be present. See Authentication and authorization for more information. Environment variable name Description AAD_TENANT_ID The tenant ID of the Azure AD. API_CLIENT_ID The application (client) ID of the TRE API service principal. API_CLIENT_SECRET The application password (client secret) of the TRE API service principal. SWAGGER_UI_CLIENT_ID The application (client) ID of the TRE Swagger UI service principal. See also: Auth in code State store Environment variable name Description STATE_STORE_ENDPOINT The Cosmos DB endpoint. Use localhost with an emulator. Example value: https://localhost:8081 STATE_STORE_KEY The Cosmos DB key. Use only with localhost emulator. COSMOSDB_ACCOUNT_NAME The Cosmos DB account name. SUBSCRIPTION_ID The Azure Subscription ID where Cosmos DB is located. RESOURCE_GROUP_NAME The Azure Resource Group name where Cosmos DB is located. Service Bus Environment variable name Description SERVICE_BUS_FULLY_QUALIFIED_NAMESPACE Example value: <your namespace>.servicebus.windows.net SERVICE_BUS_RESOURCE_REQUEST_QUEUE The queue for resource request messages sent by the API. Example value: workspacequeue SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE The queue for deployment status update messages sent by Resource Processor and received by the API. Example value: deploymentstatus Logging and monitoring Environment variable name Description APPLICATIONINSIGHTS_CONNECTION_STRING Application Insights connection string - can be left blank when debugging locally. APPINSIGHTS_INSTRUMENTATIONKEY Application Insights instrumentation key - can be left blank when debugging locally. Service principal for API process identity Environment variable name Description AZURE_SUBSCRIPTION_ID Azure Subscription ID AZURE_TENANT_ID Azure Tenant ID AZURE_CLIENT_ID API Service Principal ID AZURE_CLIENT_SECRET API Service Principal Secret Running the API Develop and run locally Install python dependencies (in a virtual environment) virtualenv venv venv/Scripts/activate pip install -r requirements.txt Copy .env.tmpl in the api_app folder to .env and configure the variables. Notice: You might also need to export those variables to your env ( export VAR_NAME=VALUE for all vars in the .env file). Start the web API cd api_app uvicorn main:app --reload The API endpoints documentation and the Swagger UI will be available at https://localhost:8000/api/docs . Develop and run in a dev container Open the project in Visual Studio Code in the DevContainer Copy .env.sample in the api_app folder to .env and configure the variables Start the web API cd api_app pip install -r requirements.txt pip install -r requirements-dev.txt uvicorn main:app --reload The API endpoints documentation and the Swagger UI will be available at https://localhost:8000/api/docs . Deploy with Docker You must have Docker and Docker Compose tools installed, and an Azure Cosmos DB configured in .env as described above. Then run: cd api_app docker compose up -d app The API will be available at https://localhost:8000/api in your browser. Unit tests The unit tests are written with pytest and located in folder /api_app/tests_ma/ . Run all unit tests with the following command in the root folder of the repository: pytest --ignore=e2e_tests API application folder structure api_app \u251c\u2500\u2500 api - API implementation \u2502 \u251c\u2500\u2500 dependencies - Dependencies for routes definition \u2502 \u251c\u2500\u2500 errors - Definitions of error handlers \u2502 \u2514\u2500\u2500 routes - Web routes (API endpoints) \u2502 \u251c\u2500\u2500 core - Application configuration, startup events, logging \u2502 \u251c\u2500\u2500 db - Database related implementation \u2502 \u251c\u2500\u2500 migrations - Manually written alembic migrations \u2502 \u2514\u2500\u2500 repositories - All CRUD features \u2502 \u251c\u2500\u2500 models - Pydantic models for this application \u2502 \u251c\u2500\u2500 domain - Main models that are used almost everywhere \u2502 \u2514\u2500\u2500 schemas - Schemas for using in web routes \u2502 \u251c\u2500\u2500 resources - Strings that are used e.g., in web responses \u2502 \u251c\u2500\u2500 services - Logic that is not only CRUD related \u2502 \u251c\u2500\u2500 tests_ma - Unit tests \u2502 \u2514\u2500\u2500 main.py - FastAPI application creation and configuration Auth in code The bulk of the authentication and authorization (A&A) related code of the API is located in /api_app/services/ folder. The A&A code has an abstract base for enabling the possibility to add additional A&A service providers. The Azure Active Directory (AAD) specific implementation is derived as follows: AccessService (access_service.py) <\u2500\u2500\u2500 AADAccessService (api_app/services/aad_authentication.py) fastapi.security.OAuth2AuthorizationCodeBearer <\u2500\u2500\u2500 AccessService (access_service.py) All the sensitive routes (API calls that can query sensitive data or modify resources) in the TRE API depend on having a \"current user\" authenticated. E.g., in /api_app/api/routes/workspaces.py : router = APIRouter ( dependencies = [ Depends ( get_current_user )]) Where APIRouter is part of the FastAPI . The user details, once authenticated, are stored as an instance of the custom User class. Auth in workspace requests Some workspace routes require authConfig field in the request body. The AAD specific implementation expects a dictionary inside data field to contain the application (client) ID of the app registration associated with workspace : { \"authConfig\" : { \"provider\" : \"AAD\" , \"data\" : { \"app_id\" : \"c36f2ee3-8ec3-4431-9240-b1c0a0eb80a0\" } } } Caution The app registration for a workspace is not created by the API. One needs to be present (created manually) before using the API to provision a new workspace. Network requirements To be able to run the TRE API it needs to access the following resource outside the Azure TRE VNET via explicit allowed Service Tags or URLs. Service Tag / Destination Justification AzureActiveDirectory Authenticate with the User Assigned identity to access Azure Cosmos DB and Azure Service Bus. AzureResourceManager To perform control plane operations, such as create database in State Store. AzureContainerRegistry Pull the TRE API container image, as it is located in Azure Container Registry. graph.microsoft.com Lookup role assignments for Azure Active Directory user, to only show TRE resources and user has access to.","title":"API"},{"location":"tre-developers/api/#tre-api","text":"The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace.","title":"TRE API"},{"location":"tre-developers/api/#prerequisites","text":"","title":"Prerequisites"},{"location":"tre-developers/api/#tools","text":"Python >= 3.8 with pip","title":"Tools"},{"location":"tre-developers/api/#azure-resources","text":"Application Insights - Not required for testing locally Azure Cosmos DB (SQL) You can use the Cosmos DB Emulator for testing locally Azure Service Bus Service principal for the API to access Azure services such as Azure Service Bus AAD applications (for the API and Swagger UI) - see Authentication & authorization for more information","title":"Azure resources"},{"location":"tre-developers/api/#creating-resources-bash","text":"The following snippets can be used to create resources for local testing with Bash shell. Sign in with Azure CLI: az login az account list az account set --subscription <subscription ID> Provision Azure Service Bus: RESOURCE_GROUP = <resource group name> LOCATION = westeurope SERVICE_BUS_NAMESPACE = <service bus namespace name> SERVICE_BUS_RESOURCE_REQUEST_QUEUE = workspacequeue SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE = deploymentstatus az servicebus namespace create --resource-group $RESOURCE_GROUP --name $SERVICE_BUS_NAMESPACE --location $LOCATION az servicebus queue create --resource-group $RESOURCE_GROUP --namespace-name $SERVICE_BUS_NAMESPACE --name $SERVICE_BUS_RESOURCE_REQUEST_QUEUE az servicebus queue create --resource-group $RESOURCE_GROUP --namespace-name $SERVICE_BUS_NAMESPACE --name $SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE Provision Azure Cosmos DB: COSMOS_NAME = <cosmos_name> COSMOS_DB_NAME = <database_name> az cosmosdb create -n $COSMOS_NAME -g $RESOURCE_GROUP --locations regionName = $LOCATION az cosmosdb sql database create -a $COSMOS_NAME -g $RESOURCE_GROUP -n $COSMOS_DB_NAME Create a service principal and assign it permissions to access Service Bus and Cosmos: az ad sp create-for-rbac --name <service principal name> SERVICE_PRINCIPAL_ID = <the AppId of the Service Principal> SUBSCRIPTION_ID = $( az account show --query id --output tsv ) az role assignment create \\ --role \"Azure Service Bus Data Sender\" \\ --assignee $SERVICE_PRINCIPAL_ID \\ --scope /subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RESOURCE_GROUP /providers/Microsoft.ServiceBus/namespaces/ $SERVICE_BUS_NAMESPACE az role assignment create \\ --role \"Azure Service Bus Data Receiver\" \\ --assignee $SERVICE_PRINCIPAL_ID \\ --scope /subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RESOURCE_GROUP /providers/Microsoft.ServiceBus/namespaces/ $SERVICE_BUS_NAMESPACE az role assignment create \\ --role \"Contributor\" \\ --assignee $SERVICE_PRINCIPAL_ID \\ --scope /subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RESOURCE_GROUP /providers/Microsoft.DocumentDB/databaseAccounts/ $COSMOS_NAME Caution Keep in mind that Azure role assignments may take up to five minutes to propagate.","title":"Creating resources (Bash)"},{"location":"tre-developers/api/#configuration","text":"","title":"Configuration"},{"location":"tre-developers/api/#general","text":"Environment variable name Description DEBUG When set to True , the debugging information for unhandled exceptions is shown in the Swagger UI and logging is more verbose. TRE_ID The Azure TRE instance name - used for deployment of resources (can be set to anything when debugging locally). Example value: mytre-dev-3142 RESOURCE_LOCATION The location (region) to deploy resources (e.g., workspaces) to. This can be set to anything as the deployment service is not called locally. Example value: westeurope","title":"General"},{"location":"tre-developers/api/#authentication-and-authorization","text":"The TRE API depends on TRE API and TRE Swagger UI app registrations. The API requires the environment variables listed in the table below to be present. See Authentication and authorization for more information. Environment variable name Description AAD_TENANT_ID The tenant ID of the Azure AD. API_CLIENT_ID The application (client) ID of the TRE API service principal. API_CLIENT_SECRET The application password (client secret) of the TRE API service principal. SWAGGER_UI_CLIENT_ID The application (client) ID of the TRE Swagger UI service principal. See also: Auth in code","title":"Authentication and Authorization"},{"location":"tre-developers/api/#state-store","text":"Environment variable name Description STATE_STORE_ENDPOINT The Cosmos DB endpoint. Use localhost with an emulator. Example value: https://localhost:8081 STATE_STORE_KEY The Cosmos DB key. Use only with localhost emulator. COSMOSDB_ACCOUNT_NAME The Cosmos DB account name. SUBSCRIPTION_ID The Azure Subscription ID where Cosmos DB is located. RESOURCE_GROUP_NAME The Azure Resource Group name where Cosmos DB is located.","title":"State store"},{"location":"tre-developers/api/#service-bus","text":"Environment variable name Description SERVICE_BUS_FULLY_QUALIFIED_NAMESPACE Example value: <your namespace>.servicebus.windows.net SERVICE_BUS_RESOURCE_REQUEST_QUEUE The queue for resource request messages sent by the API. Example value: workspacequeue SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE The queue for deployment status update messages sent by Resource Processor and received by the API. Example value: deploymentstatus","title":"Service Bus"},{"location":"tre-developers/api/#logging-and-monitoring","text":"Environment variable name Description APPLICATIONINSIGHTS_CONNECTION_STRING Application Insights connection string - can be left blank when debugging locally. APPINSIGHTS_INSTRUMENTATIONKEY Application Insights instrumentation key - can be left blank when debugging locally.","title":"Logging and monitoring"},{"location":"tre-developers/api/#service-principal-for-api-process-identity","text":"Environment variable name Description AZURE_SUBSCRIPTION_ID Azure Subscription ID AZURE_TENANT_ID Azure Tenant ID AZURE_CLIENT_ID API Service Principal ID AZURE_CLIENT_SECRET API Service Principal Secret","title":"Service principal for API process identity"},{"location":"tre-developers/api/#running-the-api","text":"","title":"Running the API"},{"location":"tre-developers/api/#develop-and-run-locally","text":"Install python dependencies (in a virtual environment) virtualenv venv venv/Scripts/activate pip install -r requirements.txt Copy .env.tmpl in the api_app folder to .env and configure the variables. Notice: You might also need to export those variables to your env ( export VAR_NAME=VALUE for all vars in the .env file). Start the web API cd api_app uvicorn main:app --reload The API endpoints documentation and the Swagger UI will be available at https://localhost:8000/api/docs .","title":"Develop and run locally"},{"location":"tre-developers/api/#develop-and-run-in-a-dev-container","text":"Open the project in Visual Studio Code in the DevContainer Copy .env.sample in the api_app folder to .env and configure the variables Start the web API cd api_app pip install -r requirements.txt pip install -r requirements-dev.txt uvicorn main:app --reload The API endpoints documentation and the Swagger UI will be available at https://localhost:8000/api/docs .","title":"Develop and run in a dev container"},{"location":"tre-developers/api/#deploy-with-docker","text":"You must have Docker and Docker Compose tools installed, and an Azure Cosmos DB configured in .env as described above. Then run: cd api_app docker compose up -d app The API will be available at https://localhost:8000/api in your browser.","title":"Deploy with Docker"},{"location":"tre-developers/api/#unit-tests","text":"The unit tests are written with pytest and located in folder /api_app/tests_ma/ . Run all unit tests with the following command in the root folder of the repository: pytest --ignore=e2e_tests","title":"Unit tests"},{"location":"tre-developers/api/#api-application-folder-structure","text":"api_app \u251c\u2500\u2500 api - API implementation \u2502 \u251c\u2500\u2500 dependencies - Dependencies for routes definition \u2502 \u251c\u2500\u2500 errors - Definitions of error handlers \u2502 \u2514\u2500\u2500 routes - Web routes (API endpoints) \u2502 \u251c\u2500\u2500 core - Application configuration, startup events, logging \u2502 \u251c\u2500\u2500 db - Database related implementation \u2502 \u251c\u2500\u2500 migrations - Manually written alembic migrations \u2502 \u2514\u2500\u2500 repositories - All CRUD features \u2502 \u251c\u2500\u2500 models - Pydantic models for this application \u2502 \u251c\u2500\u2500 domain - Main models that are used almost everywhere \u2502 \u2514\u2500\u2500 schemas - Schemas for using in web routes \u2502 \u251c\u2500\u2500 resources - Strings that are used e.g., in web responses \u2502 \u251c\u2500\u2500 services - Logic that is not only CRUD related \u2502 \u251c\u2500\u2500 tests_ma - Unit tests \u2502 \u2514\u2500\u2500 main.py - FastAPI application creation and configuration","title":"API application folder structure"},{"location":"tre-developers/api/#auth-in-code","text":"The bulk of the authentication and authorization (A&A) related code of the API is located in /api_app/services/ folder. The A&A code has an abstract base for enabling the possibility to add additional A&A service providers. The Azure Active Directory (AAD) specific implementation is derived as follows: AccessService (access_service.py) <\u2500\u2500\u2500 AADAccessService (api_app/services/aad_authentication.py) fastapi.security.OAuth2AuthorizationCodeBearer <\u2500\u2500\u2500 AccessService (access_service.py) All the sensitive routes (API calls that can query sensitive data or modify resources) in the TRE API depend on having a \"current user\" authenticated. E.g., in /api_app/api/routes/workspaces.py : router = APIRouter ( dependencies = [ Depends ( get_current_user )]) Where APIRouter is part of the FastAPI . The user details, once authenticated, are stored as an instance of the custom User class.","title":"Auth in code"},{"location":"tre-developers/api/#auth-in-workspace-requests","text":"Some workspace routes require authConfig field in the request body. The AAD specific implementation expects a dictionary inside data field to contain the application (client) ID of the app registration associated with workspace : { \"authConfig\" : { \"provider\" : \"AAD\" , \"data\" : { \"app_id\" : \"c36f2ee3-8ec3-4431-9240-b1c0a0eb80a0\" } } } Caution The app registration for a workspace is not created by the API. One needs to be present (created manually) before using the API to provision a new workspace.","title":"Auth in workspace requests"},{"location":"tre-developers/api/#network-requirements","text":"To be able to run the TRE API it needs to access the following resource outside the Azure TRE VNET via explicit allowed Service Tags or URLs. Service Tag / Destination Justification AzureActiveDirectory Authenticate with the User Assigned identity to access Azure Cosmos DB and Azure Service Bus. AzureResourceManager To perform control plane operations, such as create database in State Store. AzureContainerRegistry Pull the TRE API container image, as it is located in Azure Container Registry. graph.microsoft.com Lookup role assignments for Azure Active Directory user, to only show TRE resources and user has access to.","title":"Network requirements"},{"location":"tre-developers/end-to-end-tests/","text":"End-to-end (E2E) tests Prerequisites Authentication and Authorization configuration set up as noted here An Azure Tre deployed environment. Running the End-to-End tests locally Navigate to the e2e_tests folder: cd e2e_tests Define the following environment variables: Environment variable name Description Example value RESOURCE_LOCATION The Azure Tre deployed environment LOCATION . eastus TRE_ID The Azure TRE instance name - used for deployment of resources (can be set to anything when debugging locally). mytre-dev-3142 RESOURCE The application (client) ID of the TRE API service principal. AUTH_TENANT_ID The tenant ID of the Azure AD. CLIENT_ID The application (client) ID of the E2E Test app service principal. SCOPE Scope(s) for the token. api://<TRE API app client ID>/user_impersonation USERNAME The username of the E2E User . PASSWORD The password of the E2E User . TEST_WORKSPACE_APP_ID The application (client) ID of the workspaces app . ACR_NAME The name of the TRE container registry. Run the E2E tests: PYTHONPATH = . python -m pytest --junit-xml pytest_e2e.xml","title":"End to End Tests"},{"location":"tre-developers/end-to-end-tests/#end-to-end-e2e-tests","text":"","title":"End-to-end (E2E) tests"},{"location":"tre-developers/end-to-end-tests/#prerequisites","text":"Authentication and Authorization configuration set up as noted here An Azure Tre deployed environment.","title":"Prerequisites"},{"location":"tre-developers/end-to-end-tests/#running-the-end-to-end-tests-locally","text":"Navigate to the e2e_tests folder: cd e2e_tests Define the following environment variables: Environment variable name Description Example value RESOURCE_LOCATION The Azure Tre deployed environment LOCATION . eastus TRE_ID The Azure TRE instance name - used for deployment of resources (can be set to anything when debugging locally). mytre-dev-3142 RESOURCE The application (client) ID of the TRE API service principal. AUTH_TENANT_ID The tenant ID of the Azure AD. CLIENT_ID The application (client) ID of the E2E Test app service principal. SCOPE Scope(s) for the token. api://<TRE API app client ID>/user_impersonation USERNAME The username of the E2E User . PASSWORD The password of the E2E User . TEST_WORKSPACE_APP_ID The application (client) ID of the workspaces app . ACR_NAME The name of the TRE container registry. Run the E2E tests: PYTHONPATH = . python -m pytest --junit-xml pytest_e2e.xml","title":"Running the End-to-End tests locally"},{"location":"tre-developers/resource-processor/","text":"Resource Processor (VMSS) Resource Processor is the Azure TRE component automating Porter bundle deployments. It hosts Porter and its dependencies. Build and run the container Navigate to resource_processor/ folder and run docker build command: docker build -t resource-processor-vm-porter -f ./vmss_porter/Dockerfile . Run the image: docker run -it -v /var/run/docker.sock:/var/run/docker.sock --env-file .env resource-processor-vm-porter Local development To work locally checkout the source code and run: pip install -r ./vmss_porter/requirements.txt If you use visual studio code you can set up your launch.json to include the following block which will enable launching and debugging. { \"name\" : \"VMSS Processor\" , \"type\" : \"python\" , \"request\" : \"launch\" , \"program\" : \"vmss_porter/runner.py\" , \"console\" : \"integratedTerminal\" , \"cwd\" : \"${workspaceFolder}/resource_processor\" , \"env\" : { \"PYTHONPATH\" : \".\" , \"AZURE_CLIENT_ID\" : \"\" , \"AZURE_CLIENT_SECRET\" : \"\" , \"AZURE_TENANT_ID\" : \"\" , \"REGISTRY_SERVER\" : \"\" , \"TERRAFORM_STATE_CONTAINER_NAME\" : \"\" , \"MGMT_RESOURCE_GROUP_NAME\" : \"\" , \"MGMT_STORAGE_ACCOUNT_NAME\" : \"\" , \"SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE\" : \"deploymentstatus\" , \"SERVICE_BUS_RESOURCE_REQUEST_QUEUE\" : \"workspacequeue\" , \"SERVICE_BUS_FULLY_QUALIFIED_NAMESPACE\" : \"\" , \"ARM_CLIENT_ID\" : \"\" , \"ARM_CLIENT_SECRET\" : \"\" , \"ARM_TENANT_ID\" : \"\" , \"ARM_SUBSCRIPTION_ID\" : \"\" , \"ARM_USE_MSI\" : \"false\" } } When working locally, we use a service principal (SP). This SP needs enough permissions to be able to talk to service bus and to deploy resources into the subscription. That means the service principal needs Owner access to subscription ( ARM_SUBSCRIPTION_ID ) and also needs Azure Service Bus Data Sender and Azure Service Bus Data Receiver on the service bus namespace defined above ( SERVICE_BUS_FULLY_QUALIFIED_NAMESPACE ). Once the above is set up you can simulate receiving messages from service bus by going to service bus explorer on the portal and using a message payload for SERVICE_BUS_RESOURCE_REQUEST_QUEUE as follows { \"action\" : \"install\" , \"id\" : \"a8911125-50b4-491b-9e7c-ed8ff42220f9\" , \"name\" : \"tre-workspace-base\" , \"version\" : \"0.1.0\" , \"parameters\" : { \"azure_location\" : \"westeurope\" , \"workspace_id\" : \"20f9\" , \"tre_id\" : \"myfavtre\" , \"address_space\" : \"192.168.3.0/24\" }} This will trigger receiving of messages, and you can freely debug the code by setting breakpoints as desired. Porter Azure plugin Resource Processor uses Porter Azure plugin to store Porter data in TRE management storage account. The storage container, named porter , is created during the bootstrapping phase of TRE deployment. The /resource_processor/run.sh script generates a config.toml file in Porter home folder to enable the Azure plugin when the image is started. Debugging the deployed processor on Azure See the debugging and troubleshooting guide . Network requirements The Resource Processor needs to access the following resources outside the Azure TRE VNET via explicit allowed Service Tags or URLs. Service Tag Justification AzureActiveDirectory Authenticate with the User Assigned identity to access Azure Resource Manager and Azure Service Bus. AzureResourceManager Access the Azure control plane to deploy and manage Azure resources. AzureContainerRegistry Pull the Resource Processor container image, as it is located in Azure Container Registry. Storage The Porter bundles stores state between executions in an Azure Storage Account. AzureKeyVault The Porter bundles might need to create an Azure Key Vault inside of the Workspace. To verify the creation, before a private link connection is created, Terraform needs to reach Key Vault over public network To install Docker, Porter and related packages ( script ) on the Resource Processor, the VM must have access to download from the following URLs: packages.microsoft.com keyserver.ubuntu.com api.snapcraft.io azure.archive.ubuntu.com security.ubuntu.com entropy.ubuntu.com download.docker.com registry-1.docker.io auth.docker.io registry.terraform.io releases.hashicorp.com Challenges The notable challenges that needed to be solved included Porter automation, namely hosting environment, managing workspace (deployment) states and concurrency. Hosting the Porter runner in a container is an expected design idea and appealing due to its cost effectiveness among other things. However, that would create a nested Docker environment, \"Docker in Docker\". Although this is possible using Azure CNAB Driver , the solution is less reliable and troubleshooting becomes difficult; due to the environment's ephemeral nature, there is not much in addition to the Application Insights logs the developer can rely on. In contrast, the developer can always log in to the VM and see what's going on and run tests manually to reproduce bugs. Porter can keep tap on the installations, but Azure TRE needs a state record that is more tangible. It is instead the responsibility of the API to maintain the state of deployments in configuration store. The state is updated when a user deploys, modifies or deletes workspaces and based on the deployment status messages sent by Resource Processor. All possible states of a workspace or a workspace service are defined by the API in resource.py file .","title":"Resource Processor"},{"location":"tre-developers/resource-processor/#resource-processor-vmss","text":"Resource Processor is the Azure TRE component automating Porter bundle deployments. It hosts Porter and its dependencies.","title":"Resource Processor (VMSS)"},{"location":"tre-developers/resource-processor/#build-and-run-the-container","text":"Navigate to resource_processor/ folder and run docker build command: docker build -t resource-processor-vm-porter -f ./vmss_porter/Dockerfile . Run the image: docker run -it -v /var/run/docker.sock:/var/run/docker.sock --env-file .env resource-processor-vm-porter","title":"Build and run the container"},{"location":"tre-developers/resource-processor/#local-development","text":"To work locally checkout the source code and run: pip install -r ./vmss_porter/requirements.txt If you use visual studio code you can set up your launch.json to include the following block which will enable launching and debugging. { \"name\" : \"VMSS Processor\" , \"type\" : \"python\" , \"request\" : \"launch\" , \"program\" : \"vmss_porter/runner.py\" , \"console\" : \"integratedTerminal\" , \"cwd\" : \"${workspaceFolder}/resource_processor\" , \"env\" : { \"PYTHONPATH\" : \".\" , \"AZURE_CLIENT_ID\" : \"\" , \"AZURE_CLIENT_SECRET\" : \"\" , \"AZURE_TENANT_ID\" : \"\" , \"REGISTRY_SERVER\" : \"\" , \"TERRAFORM_STATE_CONTAINER_NAME\" : \"\" , \"MGMT_RESOURCE_GROUP_NAME\" : \"\" , \"MGMT_STORAGE_ACCOUNT_NAME\" : \"\" , \"SERVICE_BUS_DEPLOYMENT_STATUS_UPDATE_QUEUE\" : \"deploymentstatus\" , \"SERVICE_BUS_RESOURCE_REQUEST_QUEUE\" : \"workspacequeue\" , \"SERVICE_BUS_FULLY_QUALIFIED_NAMESPACE\" : \"\" , \"ARM_CLIENT_ID\" : \"\" , \"ARM_CLIENT_SECRET\" : \"\" , \"ARM_TENANT_ID\" : \"\" , \"ARM_SUBSCRIPTION_ID\" : \"\" , \"ARM_USE_MSI\" : \"false\" } } When working locally, we use a service principal (SP). This SP needs enough permissions to be able to talk to service bus and to deploy resources into the subscription. That means the service principal needs Owner access to subscription ( ARM_SUBSCRIPTION_ID ) and also needs Azure Service Bus Data Sender and Azure Service Bus Data Receiver on the service bus namespace defined above ( SERVICE_BUS_FULLY_QUALIFIED_NAMESPACE ). Once the above is set up you can simulate receiving messages from service bus by going to service bus explorer on the portal and using a message payload for SERVICE_BUS_RESOURCE_REQUEST_QUEUE as follows { \"action\" : \"install\" , \"id\" : \"a8911125-50b4-491b-9e7c-ed8ff42220f9\" , \"name\" : \"tre-workspace-base\" , \"version\" : \"0.1.0\" , \"parameters\" : { \"azure_location\" : \"westeurope\" , \"workspace_id\" : \"20f9\" , \"tre_id\" : \"myfavtre\" , \"address_space\" : \"192.168.3.0/24\" }} This will trigger receiving of messages, and you can freely debug the code by setting breakpoints as desired.","title":"Local development"},{"location":"tre-developers/resource-processor/#porter-azure-plugin","text":"Resource Processor uses Porter Azure plugin to store Porter data in TRE management storage account. The storage container, named porter , is created during the bootstrapping phase of TRE deployment. The /resource_processor/run.sh script generates a config.toml file in Porter home folder to enable the Azure plugin when the image is started.","title":"Porter Azure plugin"},{"location":"tre-developers/resource-processor/#debugging-the-deployed-processor-on-azure","text":"See the debugging and troubleshooting guide .","title":"Debugging the deployed processor on Azure"},{"location":"tre-developers/resource-processor/#network-requirements","text":"The Resource Processor needs to access the following resources outside the Azure TRE VNET via explicit allowed Service Tags or URLs. Service Tag Justification AzureActiveDirectory Authenticate with the User Assigned identity to access Azure Resource Manager and Azure Service Bus. AzureResourceManager Access the Azure control plane to deploy and manage Azure resources. AzureContainerRegistry Pull the Resource Processor container image, as it is located in Azure Container Registry. Storage The Porter bundles stores state between executions in an Azure Storage Account. AzureKeyVault The Porter bundles might need to create an Azure Key Vault inside of the Workspace. To verify the creation, before a private link connection is created, Terraform needs to reach Key Vault over public network To install Docker, Porter and related packages ( script ) on the Resource Processor, the VM must have access to download from the following URLs: packages.microsoft.com keyserver.ubuntu.com api.snapcraft.io azure.archive.ubuntu.com security.ubuntu.com entropy.ubuntu.com download.docker.com registry-1.docker.io auth.docker.io registry.terraform.io releases.hashicorp.com","title":"Network requirements"},{"location":"tre-developers/resource-processor/#challenges","text":"The notable challenges that needed to be solved included Porter automation, namely hosting environment, managing workspace (deployment) states and concurrency. Hosting the Porter runner in a container is an expected design idea and appealing due to its cost effectiveness among other things. However, that would create a nested Docker environment, \"Docker in Docker\". Although this is possible using Azure CNAB Driver , the solution is less reliable and troubleshooting becomes difficult; due to the environment's ephemeral nature, there is not much in addition to the Application Insights logs the developer can rely on. In contrast, the developer can always log in to the VM and see what's going on and run tests manually to reproduce bugs. Porter can keep tap on the installations, but Azure TRE needs a state record that is more tangible. It is instead the responsibility of the API to maintain the state of deployments in configuration store. The state is updated when a user deploys, modifies or deletes workspaces and based on the deployment status messages sent by Resource Processor. All possible states of a workspace or a workspace service are defined by the API in resource.py file .","title":"Challenges"},{"location":"tre-templates/user-resources/guacamole-linux-vm/","text":"Guacamole User Resource Service bundle (Linux) This is a User Resource Service template. It defines a Linux-based VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet. Prerequisites A base workspace bundle installed A guacamole workspace service bundle installed Manual Deployment Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/guacamole/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. PARENT_SERVICE_ID The unique identifier of this service parent (a Guacamole service) OS_IMAGE Name of the OS image to use for the VM (i.e. Ubuntu 18.04 or Ubuntu 18.04 Data Science VM ) Build and install the Guacamole Service bundle make bundle-build DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-linuxvm make bundle-install DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-linuxvm","title":"Guacamole User Resource Service bundle (Linux)"},{"location":"tre-templates/user-resources/guacamole-linux-vm/#guacamole-user-resource-service-bundle-linux","text":"This is a User Resource Service template. It defines a Linux-based VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet.","title":"Guacamole User Resource Service bundle (Linux)"},{"location":"tre-templates/user-resources/guacamole-linux-vm/#prerequisites","text":"A base workspace bundle installed A guacamole workspace service bundle installed","title":"Prerequisites"},{"location":"tre-templates/user-resources/guacamole-linux-vm/#manual-deployment","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/guacamole/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. PARENT_SERVICE_ID The unique identifier of this service parent (a Guacamole service) OS_IMAGE Name of the OS image to use for the VM (i.e. Ubuntu 18.04 or Ubuntu 18.04 Data Science VM ) Build and install the Guacamole Service bundle make bundle-build DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-linuxvm make bundle-install DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-linuxvm","title":"Manual Deployment"},{"location":"tre-templates/user-resources/guacamole-windows-vm/","text":"Guacamole User Resource Service bundle (Windows) This is a User Resource Service template. It defines a Windows 10/Server 2019 VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet. Prerequisites A base workspace bundle installed A guacamole workspace service bundle installed Manual Deployment Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/guacamole/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. PARENT_SERVICE_ID The unique identifier of this service parent (a Guacamole service) OS_IMAGE Name of the OS image to use for the VM (i.e. Windows 10 or Server 2019 Data Science VM ) Build and install the Guacamole Service bundle make bundle-build DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm make bundle-install DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm","title":"Guacamole Windows VM"},{"location":"tre-templates/user-resources/guacamole-windows-vm/#guacamole-user-resource-service-bundle-windows","text":"This is a User Resource Service template. It defines a Windows 10/Server 2019 VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet.","title":"Guacamole User Resource Service bundle (Windows)"},{"location":"tre-templates/user-resources/guacamole-windows-vm/#prerequisites","text":"A base workspace bundle installed A guacamole workspace service bundle installed","title":"Prerequisites"},{"location":"tre-templates/user-resources/guacamole-windows-vm/#manual-deployment","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/guacamole/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. PARENT_SERVICE_ID The unique identifier of this service parent (a Guacamole service) OS_IMAGE Name of the OS image to use for the VM (i.e. Windows 10 or Server 2019 Data Science VM ) Build and install the Guacamole Service bundle make bundle-build DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm make bundle-install DIR=./templates/workspace_services/guacamole/user_resources/guacamole-azure-windowsvm","title":"Manual Deployment"},{"location":"tre-templates/workspace-services/azure-ml/","text":"Azure Machine Learning Service bundle See: https://azure.microsoft.com/services/machine-learning/ This service installs the following resources into an existing virtual network within the workspace: Firewall Rules Please be aware that the following Firewall rules are opened for the workspace when this service is deployed: URLs: graph.windows.net ml.azure.com login.microsoftonline.com aadcdn.msftauth.net graph.microsoft.com management.azure.com viennaglobal.azurecr.io Service Tags: Storage. {AzureRegion} AzureContainerRegistry Prerequisites A base workspace bundle installed Manual Deployment Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/azureml/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. Build and install the Azure ML Service bundle make bundle-build DIR=./templates/workspace_services/azureml make bundle-install DIR=./templates/workspace_services/azureml","title":"Azure ML"},{"location":"tre-templates/workspace-services/azure-ml/#azure-machine-learning-service-bundle","text":"See: https://azure.microsoft.com/services/machine-learning/ This service installs the following resources into an existing virtual network within the workspace:","title":"Azure Machine Learning Service bundle"},{"location":"tre-templates/workspace-services/azure-ml/#firewall-rules","text":"Please be aware that the following Firewall rules are opened for the workspace when this service is deployed: URLs: graph.windows.net ml.azure.com login.microsoftonline.com aadcdn.msftauth.net graph.microsoft.com management.azure.com viennaglobal.azurecr.io Service Tags: Storage. {AzureRegion} AzureContainerRegistry","title":"Firewall Rules"},{"location":"tre-templates/workspace-services/azure-ml/#prerequisites","text":"A base workspace bundle installed","title":"Prerequisites"},{"location":"tre-templates/workspace-services/azure-ml/#manual-deployment","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/azureml/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. Build and install the Azure ML Service bundle make bundle-build DIR=./templates/workspace_services/azureml make bundle-install DIR=./templates/workspace_services/azureml","title":"Manual Deployment"},{"location":"tre-templates/workspace-services/dev-test-labs/","text":"Azure DevTest Labs Service bundle See: https://azure.microsoft.com/services/devtest-lab/ Prerequisites A base workspace bundle installed Manual Deployment Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/devtestlabs/.env.sample with the name .env and update with the Workspace ID used when deploying the base workspace. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. Build and install the Azure DevTest Labs Service bundle make bundle-build DIR=./templates/workspace_services/devtestlabs make bundle-install DIR=./templates/workspace_services/devtestlabs Create and expose a VM via the Firewall When this service used without a virtual desktop gateway it might be necessary to manually create and expose a VM via the TRE firewall. This method of exposing VMs is not recommended for large scale deployments given there will be multiple resources and rules to manually manage. Create a DevTest Labs VM and open a port in the TRE firewall using the script provided. Usage: ./create_and_expose_vm.sh [-l --lab-name] [-t --tre_id] [-w --workspace_id] [-n --vm-name] [-i --image-name] Options: -l, --lab-name: Name of the DevTest Lab -t, --tre_id ID of the TRE -w, --workspace_id ID of the workspace -n, --vm-name Name of the VM -i, --image-name: Name of the VM Image Example: ./templates/workspace_services/devtestlabs/create_and_expose_vm.sh --lab-name <lab_name> --tre-id <tre-id> --workspace-id <workspace-id> --vm-name <vmn-name> --image-name \"Data Science Virtual Machine - Windows Server 2019\" Using the details provided by the script, and a remote desktop connection client connect to the VM.","title":"DevTest Labs"},{"location":"tre-templates/workspace-services/dev-test-labs/#azure-devtest-labs-service-bundle","text":"See: https://azure.microsoft.com/services/devtest-lab/","title":"Azure DevTest Labs Service bundle"},{"location":"tre-templates/workspace-services/dev-test-labs/#prerequisites","text":"A base workspace bundle installed","title":"Prerequisites"},{"location":"tre-templates/workspace-services/dev-test-labs/#manual-deployment","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/devtestlabs/.env.sample with the name .env and update with the Workspace ID used when deploying the base workspace. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. Build and install the Azure DevTest Labs Service bundle make bundle-build DIR=./templates/workspace_services/devtestlabs make bundle-install DIR=./templates/workspace_services/devtestlabs","title":"Manual Deployment"},{"location":"tre-templates/workspace-services/dev-test-labs/#create-and-expose-a-vm-via-the-firewall","text":"When this service used without a virtual desktop gateway it might be necessary to manually create and expose a VM via the TRE firewall. This method of exposing VMs is not recommended for large scale deployments given there will be multiple resources and rules to manually manage. Create a DevTest Labs VM and open a port in the TRE firewall using the script provided. Usage: ./create_and_expose_vm.sh [-l --lab-name] [-t --tre_id] [-w --workspace_id] [-n --vm-name] [-i --image-name] Options: -l, --lab-name: Name of the DevTest Lab -t, --tre_id ID of the TRE -w, --workspace_id ID of the workspace -n, --vm-name Name of the VM -i, --image-name: Name of the VM Image Example: ./templates/workspace_services/devtestlabs/create_and_expose_vm.sh --lab-name <lab_name> --tre-id <tre-id> --workspace-id <workspace-id> --vm-name <vmn-name> --image-name \"Data Science Virtual Machine - Windows Server 2019\" Using the details provided by the script, and a remote desktop connection client connect to the VM.","title":"Create and expose a VM via the Firewall"},{"location":"tre-templates/workspace-services/guacamole/","text":"Guacamole Service bundle See: https://guacamole.apache.org/ Firewall Rules Please be aware that the following Firewall rules are opened for the workspace when this service is deployed: Service Tags: AzureActiveDirectory Prerequisites A base workspace bundle installed Manual Deployment Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/guacamole/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. GUACAMOLE_IMAGE_TAG The tag of the Guacamole Image to use - the tag will be the version (you can find the version in templates\\workspace\\services\\guacamole\\version.txt ) Build and install the Guacamole Service bundle make bundle-build DIR=./templates/workspace_services/guacamole make bundle-install DIR=./templates/workspace_services/guacamole","title":"Guacamole"},{"location":"tre-templates/workspace-services/guacamole/#guacamole-service-bundle","text":"See: https://guacamole.apache.org/","title":"Guacamole Service bundle"},{"location":"tre-templates/workspace-services/guacamole/#firewall-rules","text":"Please be aware that the following Firewall rules are opened for the workspace when this service is deployed: Service Tags: AzureActiveDirectory","title":"Firewall Rules"},{"location":"tre-templates/workspace-services/guacamole/#prerequisites","text":"A base workspace bundle installed","title":"Prerequisites"},{"location":"tre-templates/workspace-services/guacamole/#manual-deployment","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of templates/workspace_services/guacamole/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace service. The last 4 characters of this ID can be found in the resource names of the workspace service resources. WORKSPACE_ID The GUID identifier used when deploying the base workspace bundle. GUACAMOLE_IMAGE_TAG The tag of the Guacamole Image to use - the tag will be the version (you can find the version in templates\\workspace\\services\\guacamole\\version.txt ) Build and install the Guacamole Service bundle make bundle-build DIR=./templates/workspace_services/guacamole make bundle-install DIR=./templates/workspace_services/guacamole","title":"Manual Deployment"},{"location":"tre-templates/workspace-services/inner-eye/","text":"InnerEye DeepLearning Service Bundle Azure ML See: https://github.com/microsoft/InnerEye-DeepLearning Firewall Rules Please be aware that the following Firewall rules are opened for the workspace when this service is deployed. These are all dependencies needed by InnerEye to be able to develop and train models: URLs: *.anaconda.com *.anaconda.org binstar-cio-packages-prod.s3.amazonaws.com *pythonhosted.org github-cloud.githubusercontent.com azure.archive.ubuntu.com (git lfs package) packagecloud.io (git lfs package installation script) Initial setup Provision an InnerEye workspace by invoking a POST to https://<treid>.<region>.cloudapp.azure.com/api/workspaces with the following payload: { \"templateName\" : \"tre-workspace-innereye\" , \"properties\" : { \"display_name\" : \"InnerEye\" , \"description\" : \"InnerEyer workspace\" , \"app_id\" : \"<app_id>\" , \"inference_sp_client_id\" : \"<spn_client_id>\" , \"inference_sp_client_secret\" : \"<spn_client_secret>\" } } This will provision Base Workspace, with AML service and InnerEye service, including InnerEye Inference web app. Running the InnerEye HelloWorld Preparation steps performed by the TRE Admin Ensure that you have completed \"Configuring Shared Services\" Log onto a TREAdmin Jumpbox and mirror Github repos needed by InnerEye Helloworld: ./scripts/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-DeepLearning ./scripts/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/analysiscenter/radio ./scripts/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-Inference Setup the InnerEye run from AML Compute Instance Log onto a VM in the workspace In the VM open your browser and navigate to ml.azure.com , login, select the right Subscription and AML workspace. Select the Notebooks tab and then click Terminal. This will open a terminal on a running compute instance Pull the InnerEye-DeepLearning git repo from Gitea mirror and configure: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-DeepLearning cd InnerEye-DeepLearning curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash sudo apt-get install git-lfs git lfs install git lfs pull export PIP_INDEX_URL=https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple conda init conda env create --file environment.yml conda activate InnerEye Login to AzureCLI and set default subscription if needed az login az account set --subscription Create a \"datasets\" container az storage container create --name datasets --account-name stgws<workspace_id> 1. Copy dataset.csv file from Tests/ML/test_data/dataset.csv to the hello_world folder: az storage blob upload --account-name stgws<workspace_id> --container-name datasets --file ./Tests/ML/test_data/dataset.csv --name hello_world/dataset.csv 1. Copy the whole train_and_test_data folder from Test/ML/test_data/train_and_test_data to the hello_world folder: az storage blob directory upload -c datasets --account-name stgws<workspace_id> -s \"./Tests/ML/test_data/train_and_test_data\" -d hello_world --recursive Get storage keys for your storage: az storage account keys list --account-name stgws<workspace_id> Update the following variables in InnerEye/settings.yml : subscription_id, resource_group, workspace_name, cluster (see AML setup for more details). Navigate to Data stores in AML Workspace. Create a New datastore named innereyedatasets and link it to your storage account and datasets container. Use the key collected from the step above. Back from the Terminal run python InnerEye/ML/runner.py --model=HelloWorld --azureml=True The runner will provide you with a link and ask you to open it to login. Copy the link and open it in browser (Edge) on the DSVM and login. The run will continue after login. In your browser navigate to https://ml.azure.com and open the Experiments tab to follow the progress of the training Configuring and testing inference service The workspace service provisions an App Service Plan and an App Service for hosting the inference webapp. The webapp will be integrated into the workspace network, allowing the webapp to connect to the AML workspace. Following the setup you will need to: Log onto a VM in the workspace and run: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-Inference cd InnerEye-Inference Create a file named \"set_environment.sh\" with the following variables as content: #!/bin/bash export CUSTOMCONNSTR_AZUREML_SERVICE_PRINCIPAL_SECRET = <inference_sp_client_secret-from-above> export CUSTOMCONNSTR_API_AUTH_SECRET = <generate-a-random-guid--that-is-used-for-authentication> export CLUSTER = <name-of-compute-cluster> export WORKSPACE_NAME = <name-of-AML-workspace> export EXPERIMENT_NAME = <name-of-AML-experiment> export RESOURCE_GROUP = <name-of-resource-group> export SUBSCRIPTION_ID = <subscription-id> export APPLICATION_ID = <inference_sp_client_id-from-above> export TENANT_ID = <tenant-id> export DATASTORE_NAME = inferencedatastore export IMAGE_DATA_FOLDER = imagedata Upload the configuration file to the web app: az webapp up --name <inference-app-name> -g <resource-group-name> Create a new container in your storage account for storing inference images called inferencedatastore . Create a new folder in that container called imagedata . Navigate to the ml.azure.com, Datastores and create a new datastore named inferencedatastore and connect it to the newly created container. Test the service by sending a GET or POST command using curl or Invoke-WebRequest where API_AUTH_SECRET is the random GUID generated for CUSTOMCONNSTR_API_AUTH_SECRET above: Simple ping: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/ping -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'} Test connection with AML: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/model/start/HelloWorld:1 -Method POST -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'}","title":"InnerEye"},{"location":"tre-templates/workspace-services/inner-eye/#innereye-deeplearning-service-bundle","text":"Azure ML See: https://github.com/microsoft/InnerEye-DeepLearning","title":"InnerEye DeepLearning Service Bundle"},{"location":"tre-templates/workspace-services/inner-eye/#firewall-rules","text":"Please be aware that the following Firewall rules are opened for the workspace when this service is deployed. These are all dependencies needed by InnerEye to be able to develop and train models: URLs: *.anaconda.com *.anaconda.org binstar-cio-packages-prod.s3.amazonaws.com *pythonhosted.org github-cloud.githubusercontent.com azure.archive.ubuntu.com (git lfs package) packagecloud.io (git lfs package installation script)","title":"Firewall Rules"},{"location":"tre-templates/workspace-services/inner-eye/#initial-setup","text":"Provision an InnerEye workspace by invoking a POST to https://<treid>.<region>.cloudapp.azure.com/api/workspaces with the following payload: { \"templateName\" : \"tre-workspace-innereye\" , \"properties\" : { \"display_name\" : \"InnerEye\" , \"description\" : \"InnerEyer workspace\" , \"app_id\" : \"<app_id>\" , \"inference_sp_client_id\" : \"<spn_client_id>\" , \"inference_sp_client_secret\" : \"<spn_client_secret>\" } } This will provision Base Workspace, with AML service and InnerEye service, including InnerEye Inference web app.","title":"Initial setup"},{"location":"tre-templates/workspace-services/inner-eye/#running-the-innereye-helloworld","text":"","title":"Running the InnerEye HelloWorld"},{"location":"tre-templates/workspace-services/inner-eye/#preparation-steps-performed-by-the-tre-admin","text":"Ensure that you have completed \"Configuring Shared Services\" Log onto a TREAdmin Jumpbox and mirror Github repos needed by InnerEye Helloworld: ./scripts/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-DeepLearning ./scripts/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/analysiscenter/radio ./scripts/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-Inference","title":"Preparation steps performed by the TRE Admin"},{"location":"tre-templates/workspace-services/inner-eye/#setup-the-innereye-run-from-aml-compute-instance","text":"Log onto a VM in the workspace In the VM open your browser and navigate to ml.azure.com , login, select the right Subscription and AML workspace. Select the Notebooks tab and then click Terminal. This will open a terminal on a running compute instance Pull the InnerEye-DeepLearning git repo from Gitea mirror and configure: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-DeepLearning cd InnerEye-DeepLearning curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash sudo apt-get install git-lfs git lfs install git lfs pull export PIP_INDEX_URL=https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple conda init conda env create --file environment.yml conda activate InnerEye Login to AzureCLI and set default subscription if needed az login az account set --subscription Create a \"datasets\" container az storage container create --name datasets --account-name stgws<workspace_id> 1. Copy dataset.csv file from Tests/ML/test_data/dataset.csv to the hello_world folder: az storage blob upload --account-name stgws<workspace_id> --container-name datasets --file ./Tests/ML/test_data/dataset.csv --name hello_world/dataset.csv 1. Copy the whole train_and_test_data folder from Test/ML/test_data/train_and_test_data to the hello_world folder: az storage blob directory upload -c datasets --account-name stgws<workspace_id> -s \"./Tests/ML/test_data/train_and_test_data\" -d hello_world --recursive Get storage keys for your storage: az storage account keys list --account-name stgws<workspace_id> Update the following variables in InnerEye/settings.yml : subscription_id, resource_group, workspace_name, cluster (see AML setup for more details). Navigate to Data stores in AML Workspace. Create a New datastore named innereyedatasets and link it to your storage account and datasets container. Use the key collected from the step above. Back from the Terminal run python InnerEye/ML/runner.py --model=HelloWorld --azureml=True The runner will provide you with a link and ask you to open it to login. Copy the link and open it in browser (Edge) on the DSVM and login. The run will continue after login. In your browser navigate to https://ml.azure.com and open the Experiments tab to follow the progress of the training","title":"Setup the InnerEye run from AML Compute Instance"},{"location":"tre-templates/workspace-services/inner-eye/#configuring-and-testing-inference-service","text":"The workspace service provisions an App Service Plan and an App Service for hosting the inference webapp. The webapp will be integrated into the workspace network, allowing the webapp to connect to the AML workspace. Following the setup you will need to: Log onto a VM in the workspace and run: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-Inference cd InnerEye-Inference Create a file named \"set_environment.sh\" with the following variables as content: #!/bin/bash export CUSTOMCONNSTR_AZUREML_SERVICE_PRINCIPAL_SECRET = <inference_sp_client_secret-from-above> export CUSTOMCONNSTR_API_AUTH_SECRET = <generate-a-random-guid--that-is-used-for-authentication> export CLUSTER = <name-of-compute-cluster> export WORKSPACE_NAME = <name-of-AML-workspace> export EXPERIMENT_NAME = <name-of-AML-experiment> export RESOURCE_GROUP = <name-of-resource-group> export SUBSCRIPTION_ID = <subscription-id> export APPLICATION_ID = <inference_sp_client_id-from-above> export TENANT_ID = <tenant-id> export DATASTORE_NAME = inferencedatastore export IMAGE_DATA_FOLDER = imagedata Upload the configuration file to the web app: az webapp up --name <inference-app-name> -g <resource-group-name> Create a new container in your storage account for storing inference images called inferencedatastore . Create a new folder in that container called imagedata . Navigate to the ml.azure.com, Datastores and create a new datastore named inferencedatastore and connect it to the newly created container. Test the service by sending a GET or POST command using curl or Invoke-WebRequest where API_AUTH_SECRET is the random GUID generated for CUSTOMCONNSTR_API_AUTH_SECRET above: Simple ping: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/ping -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'} Test connection with AML: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/model/start/HelloWorld:1 -Method POST -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'}","title":"Configuring and testing inference service"},{"location":"tre-templates/workspaces/base/","text":"Azure TRE base workspace The base workspace template is the foundation that all other workspaces and workspace services are built upon. Alternative workspace architectures could be used. However, the templates provided in this repository rely on the specific architecture of this base workspace. The base workspace template contains the following resources: Virtual Network Storage Account Key Vault VNet Peer to Core VNet Network Security Group Manual Deployment Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of /templates/workspaces/base/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace. The last 4 characters of this ID can be found in the resource names of the workspace resources; for example, a ID of 2e84dad0-9d4f-42bd-8e44-3d04095eab12 will result in a resource group name for workspace of rg-<tre-id>-ab12 . ADDRESS_SPACE The address space for the workspace virtual network, must be inside the TRE_ADDRESS_SPACE defined when deploying the TRE and not overlap with any other address spaces. Build and deploy the base workspace make bundle-build DIR=./templates/workspaces/base make bundle-install DIR=./templates/workspaces/base","title":"Base"},{"location":"tre-templates/workspaces/base/#azure-tre-base-workspace","text":"The base workspace template is the foundation that all other workspaces and workspace services are built upon. Alternative workspace architectures could be used. However, the templates provided in this repository rely on the specific architecture of this base workspace. The base workspace template contains the following resources: Virtual Network Storage Account Key Vault VNet Peer to Core VNet Network Security Group","title":"Azure TRE base workspace"},{"location":"tre-templates/workspaces/base/#manual-deployment","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of /templates/workspaces/base/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace. The last 4 characters of this ID can be found in the resource names of the workspace resources; for example, a ID of 2e84dad0-9d4f-42bd-8e44-3d04095eab12 will result in a resource group name for workspace of rg-<tre-id>-ab12 . ADDRESS_SPACE The address space for the workspace virtual network, must be inside the TRE_ADDRESS_SPACE defined when deploying the TRE and not overlap with any other address spaces. Build and deploy the base workspace make bundle-build DIR=./templates/workspaces/base make bundle-install DIR=./templates/workspaces/base","title":"Manual Deployment"},{"location":"tre-templates/workspaces/inner-eye/","text":"InnerEye Deep Learning Workspace This deploys a Base workspace with the following services inside: Azure ML InnerEye Follow the links to learn more about how to access the services and any firewall rules that they will open in the workspace. Manual deployment for development and testing Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Publish the bundles required for this workspace: Base Workspace: make bundle-build DIR=./templates/workspaces/base make bundle-publish DIR=./templates/workspaces/base Azure ML Service: make bundle-build DIR=./templates/workspace_services/azureml make bundle-publish DIR=./templates/workspace_services/azureml Create a copy of workspaces/innereye/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace. The last 4 characters of this ID can be found in the resource names of the workspace resources; for example, a ID of 2e84dad0-9d4f-42bd-8e44-3d04095eab12 will result in a resource group name for workspace of rg-<tre-id>-ab12 . ADDRESS_SPACE The address space for the workspace virtual network, must be inside the TRE_ADDRESS_SPACE defined when deploying the TRE and not overlap with any other address spaces. INFERENCE_SP_CLIENT_ID Service principal client ID used by the inference service to connect to Azure ML. Use the output from the step above. INFERENCE_SP_CLIENT_SECRET Service principal client secret used by the inference service to connect to Azure ML. Use the output from the step above. Build and install the workspace: make bundle-build DIR=./templates/workspaces/innereye make bundle-install DIR=./templates/workspaces/innereye","title":"InnerEye"},{"location":"tre-templates/workspaces/inner-eye/#innereye-deep-learning-workspace","text":"This deploys a Base workspace with the following services inside: Azure ML InnerEye Follow the links to learn more about how to access the services and any firewall rules that they will open in the workspace.","title":"InnerEye Deep Learning Workspace"},{"location":"tre-templates/workspaces/inner-eye/#manual-deployment-for-development-and-testing","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Publish the bundles required for this workspace: Base Workspace: make bundle-build DIR=./templates/workspaces/base make bundle-publish DIR=./templates/workspaces/base Azure ML Service: make bundle-build DIR=./templates/workspace_services/azureml make bundle-publish DIR=./templates/workspace_services/azureml Create a copy of workspaces/innereye/.env.sample with the name .env and update the variables with the appropriate values. Environment variable name Description ID A GUID to identify the workspace. The last 4 characters of this ID can be found in the resource names of the workspace resources; for example, a ID of 2e84dad0-9d4f-42bd-8e44-3d04095eab12 will result in a resource group name for workspace of rg-<tre-id>-ab12 . ADDRESS_SPACE The address space for the workspace virtual network, must be inside the TRE_ADDRESS_SPACE defined when deploying the TRE and not overlap with any other address spaces. INFERENCE_SP_CLIENT_ID Service principal client ID used by the inference service to connect to Azure ML. Use the output from the step above. INFERENCE_SP_CLIENT_SECRET Service principal client secret used by the inference service to connect to Azure ML. Use the output from the step above. Build and install the workspace: make bundle-build DIR=./templates/workspaces/innereye make bundle-install DIR=./templates/workspaces/innereye","title":"Manual deployment for development and testing"},{"location":"tre-workspace-authors/authoring-workspace-templates/","text":"Authoring workspaces templates Azure TRE workspaces, workspace services, and user resources are Porter bundles. Porter bundles are based on Cloud Native Application Bundles (CNAB) . Workspace authors are free to choose the technology stack for provisioning resources (e.g., ARM templates, Terraform etc.), but the Azure TRE framework sets certain requirements for the bundle manifests, which specify the credentials, input and output parameters, deployment actions among other things. This document describes the requirements, and the process to author a template. Tip Use the base workspace bundle as reference or as the basis for the new bundle. To create a bundle from scratch follow the Porter Quickstart Guide ( porter create CLI command will generate a new bundle in the current directory). Background Azure TRE needed a solution for implementing and deploying workspaces and workspace services with the following properties: Means for packaging and versioning workspaces and workspace services Providing unified structure for deployment definitions (scripts, pipelines) so that the process can be easily automated Solid developer experience - easy to use and learn Porter meets all these requirements well. Porter packages cloud application into a versioned, self-contained Docker container called a Porter bundle. CNAB spec defines actions that Porter implements : install, upgrade and uninstall . The developer has practically complete freedom on how to implement logic for these actions. The deployment pipeline definition is created in YAML - something that is very familiar to anyone that have experience in creating continuous integration/deployment (CI/CD) pipelines with GitHub Actions (workflows) or in Azure DevOps . The YAML file is called Porter manifest and in additon to the actions, it contains the name, version, description of the bundle and defines the input parameters, possible credentials and output. Furthermore, Porter provides a set of mixins - analogous to the concrete actions in GitHub workflows and tasks in Azure DevOps pipelines - which simplify and reduce the development cost when implementing deployment logic. For example, Terraform mixin installs the required tools and provides a clean step in the pipeline to execute Terraform deployments. Exec mixin allows running any command or script; especially useful, if no suitable mixin for a specific technology is available. Implementing custom mixins is possible too. Prerequisites Docker installed Porter installed Azure TRE instance deployed to test against Workspace bundle manifest The manifest of a workspace bundle is the porter.yaml file (see Author Bundles in Porter documentation ). This section describes the mandatory credentials, input and output parameters of a TRE workspace bundle. Credentials A workspace bundle requires the following credentials to provision resources in Azure: Azure tenant ID Azure subscription ID The client ID of a service principal with privileges to provision resources The client secret (password) of a service principal The credentials are provided as environment variables by the deployment runner. The bundle author must use the following environment variable names: ARM_TENANT_ID ARM_SUBSCRIPTION_ID ARM_CLIENT_ID ARM_CLIENT_SECRET The names of the Porter credentials ( name field in porter.yaml ) can be freely chosen by the author. Example: credentials : - name : azure_tenant_id env : ARM_TENANT_ID - name : azure_subscription_id env : ARM_SUBSCRIPTION_ID - name : azure_client_id env : ARM_CLIENT_ID - name : azure_client_secret env : ARM_CLIENT_SECRET Parameters This section describes the mandatory (input) parameters of a workspace bundle manifest. Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e azure_location string Azure location (region) to deploy the workspace resource to. westeurope address_space string VNet address space for the workspace services. 10.2.1.0/24 tre_id can be found in the resource names of the Azure TRE instance; for example the resource group name of the Azure TRE instance based on the example in the above table would be \" rg-tre-dev-42 \". Similarly to tre_id , workspace_id is used in the resource names of the workspace. The resource group name of the workspace must be of form \" rg-<tre_id>-ws-<workspace_id> \", for example: \" rg-tre-dev-42-ws-0a9e \". All the values for the required parameters will be provided by the deployment runner. Any custom parameters are picked up by Azure TRE API and will be queried from the user deploying the workspace bundle. Custom parameters should also be defined in the template_schema.json file at the root of the bundle. This file follows the JSON schema standard and can be used by a user interface to generate a UI for the user to input the parameters. Output Todo After a workspace with virtual machines is implemented this section can be written based on that. ( Outputs in Porter documentation to be linked here too.) Actions The required actions are the main two of CNAB spec: install - Deploys/repairs the workspace Azure resources, and must be idempotent uninstall - Tears down (deletes) the Azure resources of the workspace and its services Workspace service bundle manifests Workspace service bundles are generated in the same way as workspace bundles. The mandatory parameters for workspace services are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e User resource bundle manifests User Resource bundles are generated in the same way as workspace bundles and workspace services bundles. The main difference is that a workspace service type needs to be supplied when registering a user resource template, as it only applies to a given workspace service. The mandatory parameters for User Resources are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e Versioning Workspace versions are the bundle versions specified in the metadata . The bundle versions should match the image tags in the container registry (see Publishing workspace bundle ). TRE does not provide means to update an existing workspace to a newer version. Instead, the user has to first uninstall the old version and then install the new one. The CNAB upgrade or a Porter custom (\" update \") action may be used in the future version of TRE to do this automatically. Publishing workspace bundle See Registering workspace templates .","title":"Authoring Workspace Templates"},{"location":"tre-workspace-authors/authoring-workspace-templates/#authoring-workspaces-templates","text":"Azure TRE workspaces, workspace services, and user resources are Porter bundles. Porter bundles are based on Cloud Native Application Bundles (CNAB) . Workspace authors are free to choose the technology stack for provisioning resources (e.g., ARM templates, Terraform etc.), but the Azure TRE framework sets certain requirements for the bundle manifests, which specify the credentials, input and output parameters, deployment actions among other things. This document describes the requirements, and the process to author a template. Tip Use the base workspace bundle as reference or as the basis for the new bundle. To create a bundle from scratch follow the Porter Quickstart Guide ( porter create CLI command will generate a new bundle in the current directory).","title":"Authoring workspaces templates"},{"location":"tre-workspace-authors/authoring-workspace-templates/#background","text":"Azure TRE needed a solution for implementing and deploying workspaces and workspace services with the following properties: Means for packaging and versioning workspaces and workspace services Providing unified structure for deployment definitions (scripts, pipelines) so that the process can be easily automated Solid developer experience - easy to use and learn Porter meets all these requirements well. Porter packages cloud application into a versioned, self-contained Docker container called a Porter bundle. CNAB spec defines actions that Porter implements : install, upgrade and uninstall . The developer has practically complete freedom on how to implement logic for these actions. The deployment pipeline definition is created in YAML - something that is very familiar to anyone that have experience in creating continuous integration/deployment (CI/CD) pipelines with GitHub Actions (workflows) or in Azure DevOps . The YAML file is called Porter manifest and in additon to the actions, it contains the name, version, description of the bundle and defines the input parameters, possible credentials and output. Furthermore, Porter provides a set of mixins - analogous to the concrete actions in GitHub workflows and tasks in Azure DevOps pipelines - which simplify and reduce the development cost when implementing deployment logic. For example, Terraform mixin installs the required tools and provides a clean step in the pipeline to execute Terraform deployments. Exec mixin allows running any command or script; especially useful, if no suitable mixin for a specific technology is available. Implementing custom mixins is possible too.","title":"Background"},{"location":"tre-workspace-authors/authoring-workspace-templates/#prerequisites","text":"Docker installed Porter installed Azure TRE instance deployed to test against","title":"Prerequisites"},{"location":"tre-workspace-authors/authoring-workspace-templates/#workspace-bundle-manifest","text":"The manifest of a workspace bundle is the porter.yaml file (see Author Bundles in Porter documentation ). This section describes the mandatory credentials, input and output parameters of a TRE workspace bundle.","title":"Workspace bundle manifest"},{"location":"tre-workspace-authors/authoring-workspace-templates/#credentials","text":"A workspace bundle requires the following credentials to provision resources in Azure: Azure tenant ID Azure subscription ID The client ID of a service principal with privileges to provision resources The client secret (password) of a service principal The credentials are provided as environment variables by the deployment runner. The bundle author must use the following environment variable names: ARM_TENANT_ID ARM_SUBSCRIPTION_ID ARM_CLIENT_ID ARM_CLIENT_SECRET The names of the Porter credentials ( name field in porter.yaml ) can be freely chosen by the author. Example: credentials : - name : azure_tenant_id env : ARM_TENANT_ID - name : azure_subscription_id env : ARM_SUBSCRIPTION_ID - name : azure_client_id env : ARM_CLIENT_ID - name : azure_client_secret env : ARM_CLIENT_SECRET","title":"Credentials"},{"location":"tre-workspace-authors/authoring-workspace-templates/#parameters","text":"This section describes the mandatory (input) parameters of a workspace bundle manifest. Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e azure_location string Azure location (region) to deploy the workspace resource to. westeurope address_space string VNet address space for the workspace services. 10.2.1.0/24 tre_id can be found in the resource names of the Azure TRE instance; for example the resource group name of the Azure TRE instance based on the example in the above table would be \" rg-tre-dev-42 \". Similarly to tre_id , workspace_id is used in the resource names of the workspace. The resource group name of the workspace must be of form \" rg-<tre_id>-ws-<workspace_id> \", for example: \" rg-tre-dev-42-ws-0a9e \". All the values for the required parameters will be provided by the deployment runner. Any custom parameters are picked up by Azure TRE API and will be queried from the user deploying the workspace bundle. Custom parameters should also be defined in the template_schema.json file at the root of the bundle. This file follows the JSON schema standard and can be used by a user interface to generate a UI for the user to input the parameters.","title":"Parameters"},{"location":"tre-workspace-authors/authoring-workspace-templates/#output","text":"Todo After a workspace with virtual machines is implemented this section can be written based on that. ( Outputs in Porter documentation to be linked here too.)","title":"Output"},{"location":"tre-workspace-authors/authoring-workspace-templates/#actions","text":"The required actions are the main two of CNAB spec: install - Deploys/repairs the workspace Azure resources, and must be idempotent uninstall - Tears down (deletes) the Azure resources of the workspace and its services","title":"Actions"},{"location":"tre-workspace-authors/authoring-workspace-templates/#workspace-service-bundle-manifests","text":"Workspace service bundles are generated in the same way as workspace bundles. The mandatory parameters for workspace services are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e","title":"Workspace service bundle manifests"},{"location":"tre-workspace-authors/authoring-workspace-templates/#user-resource-bundle-manifests","text":"User Resource bundles are generated in the same way as workspace bundles and workspace services bundles. The main difference is that a workspace service type needs to be supplied when registering a user resource template, as it only applies to a given workspace service. The mandatory parameters for User Resources are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e","title":"User resource bundle manifests"},{"location":"tre-workspace-authors/authoring-workspace-templates/#versioning","text":"Workspace versions are the bundle versions specified in the metadata . The bundle versions should match the image tags in the container registry (see Publishing workspace bundle ). TRE does not provide means to update an existing workspace to a newer version. Instead, the user has to first uninstall the old version and then install the new one. The CNAB upgrade or a Porter custom (\" update \") action may be used in the future version of TRE to do this automatically.","title":"Versioning"},{"location":"tre-workspace-authors/authoring-workspace-templates/#publishing-workspace-bundle","text":"See Registering workspace templates .","title":"Publishing workspace bundle"},{"location":"tre-workspace-authors/firewall-rules/","text":"Adding Firewall Rules as part of a workspace or service deployment Note Creating firewall rules will in the future only be allowed through the firewall shared services #882 . A TRE service may require certain firewall rules to be opened in the TRE firewall. Examples include: Access to an external authorisation endpoint Access to an external data store Access to an external API Please be aware when opening firewall rules there is the potential for data to be leaked from the workspace to the external location. Using Terraform to open firewall rules Until a mechanism to update shared services has been implemented, firewall rule updates should be done using terraform as part of the service deployment. The aim is to create a firewall rule that grants access from the workspace's address space to the external location. A challenge with this is that the rule must use a priority that has not been used by any other rule. Create a firewall.tf file in the terraform directory of the workspace. Add the following code to the firewall.tf file to enable the TRE firewall and workspace network to be referenced: data \"azurerm_firewall\" \"fw\" { name = \"fw-${var.tre_id}\" resource_group_name = \"rg-${var.tre_id}\" } data \"azurerm_virtual_network\" \"ws\" { name = \"vnet-${var.tre_id}-ws-${var.workspace_id}\" resource_group_name = data.azurerm_resource_group.ws.name } Define a local variable that contains the locations that access should be allowed to, and the naming format for the service resources for example: locals { allowed_urls = [ \"*.anaconda.com\", \"*.anaconda.org\" ] service_resource_name_suffix = \"${var.tre_id}-ws-${var.workspace_id}-svc-${local.service_id}\" } Log into the Azure CLI using service principal details: resource \"null_resource\" \"az_login\" { provisioner \"local-exec\" { command = \"az login --identity -u '${var.arm_client_id}'\" } triggers = { timestamp = timestamp () } } Call the get_firewall_priorities.sh script to find the next available priority: data \"external\" \"rule_priorities\" { program = [ \"bash\", \"-c\", \"./get_firewall_priorities.sh\" ] query = { firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name service_resource_name_suffix = local.service_resource_name_suffix } depends_on = [ null_resource.az_login ] } Save the get_firewall_priorities.sh script as a file in the terraform directory: #!/bin/bash set -e eval \" $( jq -r '@sh \"firewall_name=\\(.firewall_name) resource_group_name=\\(.resource_group_name) service_resource_name_suffix=\\(.service_resource_name_suffix)\"' ) \" if NETWORK_RULES = $( az network firewall network-rule list -g $resource_group_name -f $firewall_name --collection-name \"nrc- $service_resource_name_suffix \" -o json ) ; then NETWORK_RULE_PRIORITY = $( echo $NETWORK_RULES | jq '.priority' ) else NETWORK_RULE_MAX_PRIORITY = $( az network firewall network-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) NETWORK_RULE_PRIORITY = $(( $NETWORK_RULE_MAX_PRIORITY + 1 )) fi if APPLICATION_RULES = $( az network firewall application-rule list -g $resource_group_name -f $firewall_name --collection-name \"arc- $service_resource_name_suffix \" -o json ) ; then APPLICATION_RULE_PRIORITY = $( echo $APPLICATION_RULES | jq '.priority' ) else APPLICATION_RULE_MAX_PRIORITY = $( az network firewall application-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) APPLICATION_RULE_PRIORITY = $(( $APPLICATION_RULE_MAX_PRIORITY + 1 )) fi # Safely produce a JSON object containing the result value. jq -n --arg network_rule_priority \" $NETWORK_RULE_PRIORITY \" --arg application_rule_priority \" $APPLICATION_RULE_PRIORITY \" '{ \"network_rule_priority\":$network_rule_priority, \"application_rule_priority\":$application_rule_priority }' Create the firewall rule using a resource similar to the below: resource \"azurerm_firewall_application_rule_collection\" \"apprulecollection\" { name = \"arc-${local.service_resource_name_suffix}\" azure_firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name priority = data.external.rule_priorities.result.application_rule_priority action = \"Allow\" rule { name = \"allowServiceXRules\" source_addresses = data.azurerm_virtual_network.ws.address_space target_fqdns = local.allowed_urls protocol { port = \"443\" type = \"Https\" } protocol { port = \"80\" type = \"Http\" } } }","title":"Firewall Rules"},{"location":"tre-workspace-authors/firewall-rules/#adding-firewall-rules-as-part-of-a-workspace-or-service-deployment","text":"Note Creating firewall rules will in the future only be allowed through the firewall shared services #882 . A TRE service may require certain firewall rules to be opened in the TRE firewall. Examples include: Access to an external authorisation endpoint Access to an external data store Access to an external API Please be aware when opening firewall rules there is the potential for data to be leaked from the workspace to the external location.","title":"Adding Firewall Rules as part of a workspace or service deployment"},{"location":"tre-workspace-authors/firewall-rules/#using-terraform-to-open-firewall-rules","text":"Until a mechanism to update shared services has been implemented, firewall rule updates should be done using terraform as part of the service deployment. The aim is to create a firewall rule that grants access from the workspace's address space to the external location. A challenge with this is that the rule must use a priority that has not been used by any other rule. Create a firewall.tf file in the terraform directory of the workspace. Add the following code to the firewall.tf file to enable the TRE firewall and workspace network to be referenced: data \"azurerm_firewall\" \"fw\" { name = \"fw-${var.tre_id}\" resource_group_name = \"rg-${var.tre_id}\" } data \"azurerm_virtual_network\" \"ws\" { name = \"vnet-${var.tre_id}-ws-${var.workspace_id}\" resource_group_name = data.azurerm_resource_group.ws.name } Define a local variable that contains the locations that access should be allowed to, and the naming format for the service resources for example: locals { allowed_urls = [ \"*.anaconda.com\", \"*.anaconda.org\" ] service_resource_name_suffix = \"${var.tre_id}-ws-${var.workspace_id}-svc-${local.service_id}\" } Log into the Azure CLI using service principal details: resource \"null_resource\" \"az_login\" { provisioner \"local-exec\" { command = \"az login --identity -u '${var.arm_client_id}'\" } triggers = { timestamp = timestamp () } } Call the get_firewall_priorities.sh script to find the next available priority: data \"external\" \"rule_priorities\" { program = [ \"bash\", \"-c\", \"./get_firewall_priorities.sh\" ] query = { firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name service_resource_name_suffix = local.service_resource_name_suffix } depends_on = [ null_resource.az_login ] } Save the get_firewall_priorities.sh script as a file in the terraform directory: #!/bin/bash set -e eval \" $( jq -r '@sh \"firewall_name=\\(.firewall_name) resource_group_name=\\(.resource_group_name) service_resource_name_suffix=\\(.service_resource_name_suffix)\"' ) \" if NETWORK_RULES = $( az network firewall network-rule list -g $resource_group_name -f $firewall_name --collection-name \"nrc- $service_resource_name_suffix \" -o json ) ; then NETWORK_RULE_PRIORITY = $( echo $NETWORK_RULES | jq '.priority' ) else NETWORK_RULE_MAX_PRIORITY = $( az network firewall network-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) NETWORK_RULE_PRIORITY = $(( $NETWORK_RULE_MAX_PRIORITY + 1 )) fi if APPLICATION_RULES = $( az network firewall application-rule list -g $resource_group_name -f $firewall_name --collection-name \"arc- $service_resource_name_suffix \" -o json ) ; then APPLICATION_RULE_PRIORITY = $( echo $APPLICATION_RULES | jq '.priority' ) else APPLICATION_RULE_MAX_PRIORITY = $( az network firewall application-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) APPLICATION_RULE_PRIORITY = $(( $APPLICATION_RULE_MAX_PRIORITY + 1 )) fi # Safely produce a JSON object containing the result value. jq -n --arg network_rule_priority \" $NETWORK_RULE_PRIORITY \" --arg application_rule_priority \" $APPLICATION_RULE_PRIORITY \" '{ \"network_rule_priority\":$network_rule_priority, \"application_rule_priority\":$application_rule_priority }' Create the firewall rule using a resource similar to the below: resource \"azurerm_firewall_application_rule_collection\" \"apprulecollection\" { name = \"arc-${local.service_resource_name_suffix}\" azure_firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name priority = data.external.rule_priorities.result.application_rule_priority action = \"Allow\" rule { name = \"allowServiceXRules\" source_addresses = data.azurerm_virtual_network.ws.address_space target_fqdns = local.allowed_urls protocol { port = \"443\" type = \"Https\" } protocol { port = \"80\" type = \"Http\" } } }","title":"Using Terraform to open firewall rules"}]}